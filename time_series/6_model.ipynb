{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ed0d863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 10:56:54.176549: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-11 10:56:54.211906: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-11 10:56:54.225410: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-11 10:56:54.229577: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-11 10:56:54.264263: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback , ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import plotly.graph_objects as go\n",
    "from tensorflow.keras.optimizers import (\n",
    "    SGD,          # Stochastic Gradient Descent\n",
    "    RMSprop,      # Root Mean Square Propagation\n",
    "    Adam,         # Adaptive Moment Estimation\n",
    "    AdamW,        # Adam with Weight Decay\n",
    "    Nadam,        # Nesterov-accelerated Adam\n",
    "    Adagrad,      # Adaptive Gradient Algorithm\n",
    "    Adadelta,     # Adaptive Delta\n",
    "    Ftrl          # Follow-the-Regularized-Leader\n",
    ")\n",
    "import nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16273d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiunea după filtrare: 90000 rânduri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_155320/655334710.py:12: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.iloc[1:901])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "my_file = \"./pentilfuran.MDE\"\n",
    "df = pd.read_csv(\n",
    "    my_file,\n",
    "    sep=r\"\\s+\",            # înlocuiește delim_whitespace\n",
    "    comment='#',\n",
    "    names=[\"Step\", \"T\", \"E_KS\", \"E_tot\", \"Vol\", \"P\"]\n",
    ")\n",
    "\n",
    "# === Selectare rapidă a liniilor 1:901 pentru fiecare Step ===\n",
    "df_data = (\n",
    "    df.groupby(\"Step\", group_keys=False)\n",
    "      .apply(lambda g: g.iloc[1:901])\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(f\"Dimensiunea după filtrare: {len(df_data)} rânduri\")\n",
    "\n",
    "# === Extrage energia și scalează ===\n",
    "scaler = MinMaxScaler()\n",
    "energy_scaled = scaler.fit_transform(df_data[['E_tot']]).flatten()\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'Step': df_data.index,\n",
    "    'Energy_scaled': energy_scaled\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b19efdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape secvențe: (89701, 200)\n",
      "Shape ținte: (89701, 100)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === Funcție creare secvențe pentru LSTM ===\n",
    "def create_sequences(data, sequence_length, out_steps):\n",
    "    sequences, targets = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        seq = data[i:i + sequence_length]\n",
    "        target = data[i + sequence_length:i + sequence_length + out_steps]\n",
    "        if len(target) == out_steps:  # ne asigurăm că targetul e complet\n",
    "            sequences.append(seq)\n",
    "            targets.append(target)\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "# Parametrii\n",
    "sequence_length = 200\n",
    "OUT_STEPS = 100\n",
    "\n",
    "sequences, targets = create_sequences(\n",
    "    data['Energy_scaled'].values,\n",
    "    sequence_length,\n",
    "    OUT_STEPS\n",
    ")\n",
    "\n",
    "print(f\"Shape secvențe: {sequences.shape}\")\n",
    "print(f\"Shape ținte: {targets.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf216",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
