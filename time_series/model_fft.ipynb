{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22d426ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt # Adăugăm matplotlib pentru vizualizare\n",
    "from tensorflow.keras.optimizers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e201f765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddeb684e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificarea disponibilității GPU:\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "GPU detectat! Antrenarea va fi mai rapidă.\n"
     ]
    }
   ],
   "source": [
    "print(\"Verificarea disponibilității GPU:\")\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU detectat! Antrenarea va fi mai rapidă.\")\n",
    "else:\n",
    "    print(\"Niciun GPU detectat. Antrenarea va folosi CPU-ul.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8cf2086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fișierul './pentilfuran.MDE' a fost încărcat cu succes.\n",
      "Numărul total de linii de date după filtrare și concatenare: 89100\n"
     ]
    }
   ],
   "source": [
    "# Celula 3: Încărcarea și pregătirea datelor\n",
    "my_file = \"./pentilfuran.MDE\"\n",
    "try:\n",
    "    # Modificare aici: înlocuim delim_whitespace=True cu sep='\\s+'\n",
    "    df = pd.read_csv(my_file, sep='\\s+', comment='#', names=[\"Step\", \"T\", \"E_KS\", \"E_tot\", \"Vol\", \"P\"])\n",
    "    print(f\"Fișierul '{my_file}' a fost încărcat cu succes.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Eroare: Fișierul '{my_file}' nu a fost găsit. Se va folosi un DataFrame mock pentru demonstrație.\")\n",
    "    # Creăm un DataFrame mock cu 90k linii pentru a simula datele reale\n",
    "    num_mock_rows = 90000\n",
    "    data_mock = {\n",
    "        \"Step\": list(range(1, 101)) * (num_mock_rows // 100),\n",
    "        \"T\": np.random.rand(num_mock_rows) * 50 + 1.45,\n",
    "        \"E_KS\": np.sin(np.linspace(0, 2 * np.pi * num_mock_rows / 50, num_mock_rows)) * 0.2 + np.random.rand(num_mock_rows) * 0.01 - 2130.9,\n",
    "        \"E_tot\": np.random.rand(num_mock_rows) * 0.1 - 2130.9,\n",
    "        \"Vol\": [3287.283] * num_mock_rows,\n",
    "        \"P\": np.random.rand(num_mock_rows) * 1 - 0.5\n",
    "    }\n",
    "    df = pd.DataFrame(data_mock)\n",
    "    print(\"DataFrame mock generat.\")\n",
    "\n",
    "\n",
    "# Filtrarea și concatenarea datelor pe baza 'Step'\n",
    "# Presupunem că vrei 900 de rânduri per bloc (de la index 1 la 900)\n",
    "# Dacă vrei toate rândurile din fiecare bloc, folosește `iloc[:]` în loc de `iloc[1:901]`\n",
    "dfs = [df[df['Step'] == i].iloc[1:901] for i in range(1, 100)]\n",
    "df_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(f\"Numărul total de linii de date după filtrare și concatenare: {len(df_data)}\")\n",
    "\n",
    "# Extrage coloana E_KS (Energia K) pentru predicție\n",
    "# `global_step_index` este indexul global al datelor concatenate\n",
    "global_step_index = df_data.index.values \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8241df82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caracteristici de intrare pentru model: ['E_KS', 'sin_feature', 'cos_feature']\n",
      "Numărul de caracteristici de intrare: 3\n"
     ]
    }
   ],
   "source": [
    "# Celula 4: Ingineria Caracteristicilor (Adăugarea Frecvențelor Dominante)\n",
    "# Frecvența dominantă identificată de FFT este 0.02 Hz (cicluri per pas)\n",
    "dominant_frequency = 0.02\n",
    "\n",
    "# Calculează caracteristicile sinusoidale și cosinusoidale\n",
    "# Folosim `global_step_index` pentru a asigura continuitatea fazei pe întregul set de date\n",
    "df_data['sin_feature'] = np.sin(2 * np.pi * dominant_frequency * global_step_index)\n",
    "df_data['cos_feature'] = np.cos(2 * np.pi * dominant_frequency * global_step_index)\n",
    "\n",
    "# Coloanele pe care le vom scala și folosi ca intrări pentru model\n",
    "features_to_scale = ['E_KS', 'sin_feature', 'cos_feature']\n",
    "# Scalăm toate caracteristicile relevante\n",
    "scaler = MinMaxScaler()\n",
    "df_data[features_to_scale] = scaler.fit_transform(df_data[features_to_scale])\n",
    "\n",
    "# Numărul de caracteristici de intrare pentru model\n",
    "num_features = len(features_to_scale)\n",
    "\n",
    "print(f\"Caracteristici de intrare pentru model: {features_to_scale}\")\n",
    "print(f\"Numărul de caracteristici de intrare: {num_features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "796e77eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma secvențelor de intrare: (88801, 200, 3)\n",
      "Forma țintelor (ieșire): (88801, 100)\n"
     ]
    }
   ],
   "source": [
    "# Celula 5: Crearea secvențelor de time-series\n",
    "def create_sequences(data, sequence_length, output_steps):\n",
    "    \"\"\"\n",
    "    Creează secvențe de intrare și ținte pentru un model de time-series.\n",
    "    \n",
    "    Args:\n",
    "        data (np.array): Datele de intrare (caracteristici multiple).\n",
    "        sequence_length (int): Lungimea secvenței de intrare.\n",
    "        output_steps (int): Numărul de pași viitori de prezis.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (sequences, targets) - array-uri numpy cu secvențele de intrare și țintele.\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    # Iterează până la (lungimea datelor - lungimea secvenței de intrare - lungimea secvenței de ieșire)\n",
    "    for i in range(len(data) - sequence_length - output_steps + 1):\n",
    "        seq = data[i : (i + sequence_length)]\n",
    "        # Prezicem doar E_KS (prima coloană, index 0)\n",
    "        target = data[(i + sequence_length) : (i + sequence_length + output_steps), 0] \n",
    "        sequences.append(seq)\n",
    "        targets.append(target)\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "# Definirea lungimii secvenței și a pașilor de ieșire\n",
    "sequence_length = 200 # Lungimea secvenței de intrare\n",
    "OUT_STEPS = 100       # Numărul de pași viitori de prezis\n",
    "\n",
    "# Pregătim datele pentru funcția create_sequences\n",
    "# Folosim toate caracteristicile scalate\n",
    "data_for_sequences = df_data[features_to_scale].values\n",
    "\n",
    "sequences, targets = create_sequences(data_for_sequences, sequence_length, OUT_STEPS)\n",
    "print(f\"Forma secvențelor de intrare: {sequences.shape}\")\n",
    "print(f\"Forma țintelor (ieșire): {targets.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d85927d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma X_train: (66600, 200, 3), Y_train: (66600, 100, 1)\n",
      "Forma X_val: (17760, 200, 3), Y_val: (17760, 100, 1)\n",
      "Forma X_test: (4441, 200, 3), Y_test: (4441, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "# Celula 6: Împărțirea datelor în seturi de antrenament, validare și testare\n",
    "# Asigurăm că split-ul este consistent cu datele tale de 90k linii\n",
    "# Calculează dimensiunile seturilor\n",
    "total_sequences = len(sequences)\n",
    "train_size = int(0.75 * total_sequences) \n",
    "val_size = int(0.20 * total_sequences)   \n",
    "test_size = total_sequences - train_size - val_size \n",
    "\n",
    "X_train, y_train = sequences[:train_size], targets[:train_size]\n",
    "X_val, y_val = sequences[train_size : train_size + val_size], targets[train_size : train_size + val_size]\n",
    "X_test, y_test = sequences[train_size + val_size :], targets[train_size + val_size :]\n",
    "\n",
    "# Reshape pentru modelul Keras (num_samples, timesteps, num_features)\n",
    "# y_train, y_val, y_test trebuie să fie reshaped la (num_samples, OUT_STEPS, 1)\n",
    "y_train = y_train.reshape((y_train.shape[0], y_train.shape[1], 1))\n",
    "y_val = y_val.reshape((y_val.shape[0], y_val.shape[1], 1))\n",
    "y_test = y_test.reshape((y_test.shape[0], y_test.shape[1], 1))\n",
    "\n",
    "print(f\"Forma X_train: {X_train.shape}, Y_train: {y_train.shape}\")\n",
    "print(f\"Forma X_val: {X_val.shape}, Y_val: {y_val.shape}\")\n",
    "print(f\"Forma X_test: {X_test.shape}, Y_test: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5296942",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1754386029.992125    5938 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1754386029.992332    5938 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1754386029.992461    5938 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1754386030.061859    5938 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1754386030.062069    5938 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1754386030.062199    5938 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-05 12:27:10.062320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6302 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "W0000 00:00:1754386030.656347    6904 gpu_backend_lib.cc:593] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
      "Searched for CUDA in the following directories:\n",
      "  ./cuda_sdk_lib\n",
      "  /home/conda/feedstock_root/build_artifacts/tensorflow-split_1729095706337/_build_env/targets/x86_64-linux\n",
      "  /usr/local/cuda\n",
      "  /home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/tensorflow/python/platform/../../../nvidia/cuda_nvcc\n",
      "  /home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/tensorflow/python/platform/../../../../nvidia/cuda_nvcc\n",
      "  .\n",
      "You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">82,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,900</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │         \u001b[38;5;34m1,280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m82,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m24,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m164,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m66,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m12,900\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">714,404</span> (2.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m714,404\u001b[0m (2.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">713,764</span> (2.72 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m713,764\u001b[0m (2.72 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> (2.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m640\u001b[0m (2.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Celula 7: Definirea Modelului Hibrid CNN-LSTM\n",
    "def create_improved_hybrid_model(sequence_length, num_features, output_steps):\n",
    "    \"\"\"\n",
    "    Creează un model hibrid CNN-LSTM îmbunătățit pentru predicția seriilor de timp.\n",
    "    \n",
    "    Args:\n",
    "        sequence_length (int): Lungimea secvenței de intrare.\n",
    "        num_features (int): Numărul de caracteristici de intrare.\n",
    "        output_steps (int): Numărul de pași viitori de prezis.\n",
    "        \n",
    "    Returns:\n",
    "        tf.keras.Model: Modelul Keras compilat.\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.Input(shape=(sequence_length, num_features)), # Input cu num_features\n",
    "        tf.keras.layers.Conv1D(filters=128, kernel_size=3, activation='relu', padding='causal'), \n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        \n",
    "        tf.keras.layers.Conv1D(filters=128, kernel_size=5, activation='relu', padding='causal'), \n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        \n",
    "        tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu', padding='causal'), \n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        \n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True, \n",
    "                                                          dropout=0.1, recurrent_dropout=0.1)),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, dropout=0.1, recurrent_dropout=0.1)),\n",
    "        \n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        \n",
    "        # Stratul de ieșire: prezice OUT_STEPS valori pentru o singură caracteristică (E_KS)\n",
    "        tf.keras.layers.Dense(output_steps * 1), \n",
    "        tf.keras.layers.Reshape([output_steps, 1]) \n",
    "    ])\n",
    "    model.summary() # Afișează sumarul modelului\n",
    "    return model\n",
    "\n",
    "# Inițializează modelul cu numărul corect de caracteristici\n",
    "model_hybrid = create_improved_hybrid_model(sequence_length, num_features, OUT_STEPS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7eb3a56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celula 8: Definirea Callback-urilor și a Funcției de Antrenament\n",
    "# Callbacks for training\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=8, # Mărit răbdarea\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=\"best_hybrid_model_with_fourier.keras\", # Nume nou pentru fișierul modelului salvat\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.7, # Factor de reducere\n",
    "    patience=5, # Răbdare pentru reducerea learning rate-ului\n",
    "    min_lr=1e-6, # Learning rate minim\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "def compile_and_fit_improved(model, X_train, y_train, X_val, y_val, epochs=30, batch_size=32):\n",
    "    \"\"\"\n",
    "    Compilează și antrenează modelul cu optimizator și callback-uri îmbunătățite.\n",
    "    \n",
    "    Args:\n",
    "        model (tf.keras.Model): Modelul Keras de antrenat.\n",
    "        X_train (np.array): Datele de antrenament (intrări).\n",
    "        y_train (np.array): Țintele de antrenament.\n",
    "        X_val (np.array): Datele de validare (intrări).\n",
    "        y_val (np.array): Țintele de validare.\n",
    "        epochs (int): Numărul maxim de epoci.\n",
    "        batch_size (int): Dimensiunea batch-ului.\n",
    "        \n",
    "    Returns:\n",
    "        tf.keras.callbacks.History: Obiectul History returnat de model.fit.\n",
    "    \"\"\"\n",
    "    optimizer = AdamW(\n",
    "        learning_rate=0.0005,  # Learning rate mai mic\n",
    "        weight_decay=0.01\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='huber',  # Mai robust decât MSE pentru outliers\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    callbacks = [\n",
    "        early_stopping,\n",
    "        reduce_lr,\n",
    "        model_checkpoint\n",
    "    ]\n",
    "    \n",
    "    print(f\"Începe antrenarea modelului pentru maxim {epochs} epoci cu batch_size={batch_size}...\")\n",
    "    history = model.fit(\n",
    "        X_train, y_train, \n",
    "        epochs=epochs, \n",
    "        batch_size=batch_size,  # Batch size mai mare\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f3a1b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Începe antrenarea modelului pentru maxim 30 epoci cu batch_size=32...\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 12:27:52.703373: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 91001\n",
      "W0000 00:00:1754386072.816259    6895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1754386072.839219    6895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1754386072.845624    6895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1754386072.846379    6895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1754386072.847135    6895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1754386072.873968    6895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1754386072.874735    6895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1754386072.877708    6895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1754386072.880386    6895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1754386072.881226    6895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1754386072.883405    6895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1754386072.891013    6895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1754386072.892643    6895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1754386072.894937    6895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1754386072.895702    6895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1754386072.896471    6895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1754386072.897242    6895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1754386072.899140    6895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1754386072.899995    6895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1754386072.907901    6895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1754386072.974330    7024 gpu_backend_lib.cc:631] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "W0000 00:00:1754386072.975052    7012 gpu_backend_lib.cc:631] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "W0000 00:00:1754386072.975704    7010 gpu_backend_lib.cc:631] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "W0000 00:00:1754386072.976408    7014 gpu_backend_lib.cc:631] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "W0000 00:00:1754386072.977128    7019 gpu_backend_lib.cc:631] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "W0000 00:00:1754386072.977819    7022 gpu_backend_lib.cc:631] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "W0000 00:00:1754386072.978529    7015 gpu_backend_lib.cc:631] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "W0000 00:00:1754386072.979178    7020 gpu_backend_lib.cc:631] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "error: libdevice not found at ./libdevice.10.bc\n",
      "error: libdevice not found at ./libdevice.10.bc\n",
      "error: libdevice not found at ./libdevice.10.bc\n",
      "error: libdevice not found at ./libdevice.10.bc\n",
      "error: libdevice not found at ./libdevice.10.bc\n",
      "error: libdevice not found at ./libdevice.10.bc\n",
      "error: libdevice not found at ./libdevice.10.bc\n",
      "error: libdevice not found at ./libdevice.10.bc\n",
      "2025-08-05 12:27:52.979426: E tensorflow/compiler/mlir/tools/kernel_gen/tf_framework_c_interface.cc:228] INTERNAL: Generating device code failed.\n",
      "2025-08-05 12:27:52.980130: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980154: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: UNKNOWN: JIT compilation failed.\n",
      "\t [[{{function_node __inference_one_step_on_data_18678}}{{node adamw/Pow_43}}]]\n",
      "2025-08-05 12:27:52.980163: I tensorflow/core/framework/local_rendezvous.cc:427] Local rendezvous send item cancelled. Key hash: 13711207258916380940\n",
      "2025-08-05 12:27:52.980169: I tensorflow/core/framework/local_rendezvous.cc:427] Local rendezvous send item cancelled. Key hash: 11456636115102162926\n",
      "2025-08-05 12:27:52.980177: I tensorflow/core/framework/local_rendezvous.cc:427] Local rendezvous send item cancelled. Key hash: 8705853362639288467\n",
      "2025-08-05 12:27:52.980185: I tensorflow/core/framework/local_rendezvous.cc:427] Local rendezvous send item cancelled. Key hash: 6868420953895883137\n",
      "2025-08-05 12:27:52.980190: I tensorflow/core/framework/local_rendezvous.cc:427] Local rendezvous send item cancelled. Key hash: 5589684904440709939\n",
      "2025-08-05 12:27:52.980217: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980225: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980232: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980240: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980249: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980256: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980263: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980270: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980278: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980285: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980291: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980298: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980306: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980316: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980325: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980333: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980341: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980348: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980357: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980365: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980373: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980379: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980386: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980397: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980405: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980412: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980420: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980428: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980435: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980442: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980462: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980471: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980480: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980487: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980497: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980505: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980515: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980525: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980535: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980542: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980553: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980563: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980573: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980583: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980595: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980605: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980614: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980624: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980633: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980642: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980650: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980659: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980668: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980677: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980684: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980695: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980706: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980714: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980722: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980733: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980751: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980759: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "2025-08-05 12:27:52.980766: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n",
      "W0000 00:00:1754386073.213127    6895 gpu_backend_lib.cc:631] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "error: libdevice not found at ./libdevice.10.bc\n",
      "2025-08-05 12:27:53.213284: E tensorflow/compiler/mlir/tools/kernel_gen/tf_framework_c_interface.cc:228] INTERNAL: Generating device code failed.\n",
      "2025-08-05 12:27:53.213578: W tensorflow/core/framework/op_kernel.cc:1828] UNKNOWN: JIT compilation failed.\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nDetected at node adamw/Pow_43 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n\n  File \"/tmp/ipykernel_5938/220854830.py\", line 2, in <module>\n\n  File \"/tmp/ipykernel_5938/1167740463.py\", line 59, in compile_and_fit_improved\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 114, in one_step_on_data\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 81, in train_step\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\", line 463, in apply_gradients\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\", line 527, in apply\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\", line 593, in _backend_apply_gradients\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 120, in _backend_update_step\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 134, in _distributed_tf_update_step\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 131, in apply_grad_to_update_var\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/keras/src/optimizers/adam.py\", line 110, in update_step\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/keras/src/ops/numpy.py\", line 6391, in power\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/keras/src/backend/tensorflow/numpy.py\", line 2653, in power\n\nJIT compilation failed.\n\t [[{{node adamw/Pow_43}}]] [Op:__inference_multi_step_on_iterator_18915]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnknownError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Celula 9: Antrenarea Modelului\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m history = \u001b[43mcompile_and_fit_improved\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_hybrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 59\u001b[39m, in \u001b[36mcompile_and_fit_improved\u001b[39m\u001b[34m(model, X_train, y_train, X_val, y_val, epochs, batch_size)\u001b[39m\n\u001b[32m     52\u001b[39m callbacks = [\n\u001b[32m     53\u001b[39m     early_stopping,\n\u001b[32m     54\u001b[39m     reduce_lr,\n\u001b[32m     55\u001b[39m     model_checkpoint\n\u001b[32m     56\u001b[39m ]\n\u001b[32m     58\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mÎncepe antrenarea modelului pentru maxim \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m epoci cu batch_size=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Batch size mai mare\u001b[39;49;00m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     66\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf216/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf216/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[32m     54\u001b[39m                                       inputs, attrs, num_outputs)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mUnknownError\u001b[39m: Graph execution error:\n\nDetected at node adamw/Pow_43 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n\n  File \"/tmp/ipykernel_5938/220854830.py\", line 2, in <module>\n\n  File \"/tmp/ipykernel_5938/1167740463.py\", line 59, in compile_and_fit_improved\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 114, in one_step_on_data\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 81, in train_step\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\", line 463, in apply_gradients\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\", line 527, in apply\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\", line 593, in _backend_apply_gradients\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 120, in _backend_update_step\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 134, in _distributed_tf_update_step\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 131, in apply_grad_to_update_var\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/keras/src/optimizers/adam.py\", line 110, in update_step\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/keras/src/ops/numpy.py\", line 6391, in power\n\n  File \"/home/glosper/anaconda3/envs/tf216/lib/python3.11/site-packages/keras/src/backend/tensorflow/numpy.py\", line 2653, in power\n\nJIT compilation failed.\n\t [[{{node adamw/Pow_43}}]] [Op:__inference_multi_step_on_iterator_18915]"
     ]
    }
   ],
   "source": [
    "# Celula 9: Antrenarea Modelului\n",
    "history = compile_and_fit_improved(model_hybrid, X_train, y_train, X_val, y_val, epochs=30, batch_size=32)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf216",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
