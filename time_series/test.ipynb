{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d9f45f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 11:21:25.712190: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-11 11:21:25.721650: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-11 11:21:25.733406: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-11 11:21:25.736717: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-11 11:21:25.746660: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Libraries importate cu succes!\n",
      "üìä Dimensiune date originale: (93300, 6)\n",
      "üìã Coloane disponibile: ['Step', 'T', 'E_KS', 'E_tot', 'Vol', 'P']\n",
      "üî¢ NumƒÉrul de steps unici: 100\n",
      "‚úÖ Dimensiunea dupƒÉ filtrare: 90000 r√¢nduri\n",
      "üìà Range energie totalƒÉ: [-2131.327240, -2130.745750]\n",
      "üå°Ô∏è Range temperaturƒÉ: [1.4500, 53.0400]\n",
      "\n",
      "üîç Valori lipsƒÉ per coloanƒÉ:\n",
      "Step     0\n",
      "T        0\n",
      "E_KS     0\n",
      "E_tot    0\n",
      "Vol      0\n",
      "P        0\n",
      "dtype: int64\n",
      "üîç AnalizƒÉ periodicitate cu FFT...\n",
      "üéØ Top 10 frecven»õe dominante:\n",
      "    1. Freq: 0.020000 Hz, PerioadƒÉ:    50.00 pa»ôi, Putere: 7.49e+03\n",
      "    2. Freq: 0.021111 Hz, PerioadƒÉ:    47.37 pa»ôi, Putere: 4.20e+03\n",
      "    3. Freq: 0.001111 Hz, PerioadƒÉ:   900.00 pa»ôi, Putere: 3.00e+03\n",
      "    4. Freq: 0.018889 Hz, PerioadƒÉ:    52.94 pa»ôi, Putere: 2.06e+03\n",
      "    5. Freq: 0.041111 Hz, PerioadƒÉ:    24.32 pa»ôi, Putere: 1.78e+03\n",
      "    6. Freq: 0.002222 Hz, PerioadƒÉ:   450.00 pa»ôi, Putere: 1.54e+03\n",
      "    7. Freq: 0.022222 Hz, PerioadƒÉ:    45.00 pa»ôi, Putere: 1.53e+03\n",
      "    8. Freq: 0.017778 Hz, PerioadƒÉ:    56.25 pa»ôi, Putere: 1.20e+03\n",
      "    9. Freq: 0.023333 Hz, PerioadƒÉ:    42.86 pa»ôi, Putere: 8.92e+02\n",
      "   10. Freq: 0.015556 Hz, PerioadƒÉ:    64.29 pa»ôi, Putere: 8.37e+02\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "blue"
         },
         "name": "Original",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999
         ],
         "xaxis": "x",
         "y": [
          -2131.04545,
          -2131.06881,
          -2131.09338,
          -2131.11948,
          -2131.14642,
          -2131.17316,
          -2131.19881,
          -2131.22257,
          -2131.24331,
          -2131.26095,
          -2131.27396,
          -2131.28305,
          -2131.28723,
          -2131.28552,
          -2131.27878,
          -2131.26805,
          -2131.25265,
          -2131.23291,
          -2131.21081,
          -2131.18521,
          -2131.15894,
          -2131.13211,
          -2131.10519,
          -2131.07926,
          -2131.055,
          -2131.033,
          -2131.0131,
          -2130.99575,
          -2130.98142,
          -2130.96943,
          -2130.96005,
          -2130.95303,
          -2130.94795,
          -2130.94437,
          -2130.94194,
          -2130.94038,
          -2130.93964,
          -2130.93942,
          -2130.93983,
          -2130.94085,
          -2130.94278,
          -2130.94578,
          -2130.95013,
          -2130.95622,
          -2130.96452,
          -2130.97506,
          -2130.988,
          -2131.00389,
          -2131.02259,
          -2131.04365,
          -2131.06747,
          -2131.09239,
          -2131.11906,
          -2131.14652,
          -2131.1739,
          -2131.19984,
          -2131.22401,
          -2131.24541,
          -2131.26332,
          -2131.27673,
          -2131.28605,
          -2131.29034,
          -2131.28855,
          -2131.28161,
          -2131.27046,
          -2131.25451,
          -2131.23409,
          -2131.21107,
          -2131.18451,
          -2131.15717,
          -2131.12914,
          -2131.10093,
          -2131.07349,
          -2131.04772,
          -2131.02418,
          -2131.00278,
          -2130.98417,
          -2130.96835,
          -2130.95543,
          -2130.94518,
          -2130.93731,
          -2130.93172,
          -2130.9275,
          -2130.92481,
          -2130.92301,
          -2130.92217,
          -2130.92193,
          -2130.92242,
          -2130.92351,
          -2130.92568,
          -2130.9291,
          -2130.934,
          -2130.94081,
          -2130.94984,
          -2130.96158,
          -2130.97591,
          -2130.99343,
          -2131.01422,
          -2131.03762,
          -2131.06418,
          -2131.09196,
          -2131.12157,
          -2131.15198,
          -2131.18237,
          -2131.21131,
          -2131.2382,
          -2131.26188,
          -2131.28195,
          -2131.29684,
          -2131.30727,
          -2131.31201,
          -2131.31006,
          -2131.30228,
          -2131.28989,
          -2131.27208,
          -2131.24931,
          -2131.22363,
          -2131.19387,
          -2131.16329,
          -2131.13229,
          -2131.10108,
          -2131.07082,
          -2131.04267,
          -2131.01718,
          -2130.9943,
          -2130.97428,
          -2130.95759,
          -2130.94384,
          -2130.93315,
          -2130.92515,
          -2130.91947,
          -2130.91534,
          -2130.91268,
          -2130.91102,
          -2130.91024,
          -2130.91001,
          -2130.91048,
          -2130.91151,
          -2130.91357,
          -2130.91674,
          -2130.92136,
          -2130.92821,
          -2130.93746,
          -2130.94957,
          -2130.96453,
          -2130.98292,
          -2131.00487,
          -2131.02975,
          -2131.05815,
          -2131.08816,
          -2131.12001,
          -2131.15312,
          -2131.18603,
          -2131.21733,
          -2131.24671,
          -2131.27254,
          -2131.29435,
          -2131.31058,
          -2131.32201,
          -2131.32724,
          -2131.3251,
          -2131.31665,
          -2131.30307,
          -2131.28359,
          -2131.25866,
          -2131.23081,
          -2131.19837,
          -2131.16534,
          -2131.13173,
          -2131.09806,
          -2131.06584,
          -2131.03564,
          -2131.00884,
          -2130.98457,
          -2130.96393,
          -2130.9469,
          -2130.93297,
          -2130.92263,
          -2130.91496,
          -2130.90955,
          -2130.90569,
          -2130.90329,
          -2130.90185,
          -2130.90119,
          -2130.90098,
          -2130.90134,
          -2130.90221,
          -2130.90392,
          -2130.90673,
          -2130.91087,
          -2130.91731,
          -2130.92591,
          -2130.93751,
          -2130.95181,
          -2130.9698,
          -2130.99145,
          -2131.01591,
          -2131.04402,
          -2131.07365,
          -2131.10572,
          -2131.13901,
          -2131.1727,
          -2131.20484,
          -2131.23498,
          -2131.26179,
          -2131.28442,
          -2131.30136,
          -2131.31325,
          -2131.31869,
          -2131.31644,
          -2131.30763,
          -2131.29355,
          -2131.27344,
          -2131.24787,
          -2131.21929,
          -2131.18668,
          -2131.1532,
          -2131.11931,
          -2131.08587,
          -2131.05387,
          -2131.02501,
          -2130.9984,
          -2130.97509,
          -2130.95496,
          -2130.93862,
          -2130.92526,
          -2130.91506,
          -2130.90754,
          -2130.90201,
          -2130.89817,
          -2130.89578,
          -2130.89436,
          -2130.89364,
          -2130.89342,
          -2130.89384,
          -2130.89483,
          -2130.89685,
          -2130.89993,
          -2130.90474,
          -2130.91157,
          -2130.92089,
          -2130.93269,
          -2130.94765,
          -2130.96657,
          -2130.98899,
          -2131.01452,
          -2131.04299,
          -2131.07368,
          -2131.1059,
          -2131.13944,
          -2131.17299,
          -2131.20481,
          -2131.2347,
          -2131.26096,
          -2131.28293,
          -2131.29933,
          -2131.31071,
          -2131.31591,
          -2131.31378,
          -2131.30554,
          -2131.29226,
          -2131.27336,
          -2131.24919,
          -2131.22196,
          -2131.19079,
          -2131.15846,
          -2131.12577,
          -2131.09295,
          -2131.06132,
          -2131.0318,
          -2131.00522,
          -2130.98123,
          -2130.96036,
          -2130.94261,
          -2130.92807,
          -2130.91679,
          -2130.90829,
          -2130.90214,
          -2130.89767,
          -2130.89481,
          -2130.8929,
          -2130.89199,
          -2130.89174,
          -2130.89224,
          -2130.8934,
          -2130.89574,
          -2130.89932,
          -2130.90439,
          -2130.91169,
          -2130.9213,
          -2130.93398,
          -2130.9493,
          -2130.96803,
          -2130.99022,
          -2131.0147,
          -2131.04262,
          -2131.07202,
          -2131.10332,
          -2131.13526,
          -2131.16714,
          -2131.19747,
          -2131.2258,
          -2131.25079,
          -2131.27203,
          -2131.28781,
          -2131.29887,
          -2131.30395,
          -2131.30184,
          -2131.29363,
          -2131.28044,
          -2131.26154,
          -2131.23731,
          -2131.21022,
          -2131.1787,
          -2131.1462,
          -2131.11307,
          -2131.07964,
          -2131.04759,
          -2131.01783,
          -2130.99103,
          -2130.96677,
          -2130.94573,
          -2130.92825,
          -2130.91361,
          -2130.90236,
          -2130.89387,
          -2130.88787,
          -2130.88371,
          -2130.88106,
          -2130.87937,
          -2130.87851,
          -2130.87829,
          -2130.87875,
          -2130.87986,
          -2130.88208,
          -2130.88545,
          -2130.8904,
          -2130.89741,
          -2130.90667,
          -2130.9191,
          -2130.93418,
          -2130.95273,
          -2130.97489,
          -2130.99972,
          -2131.02792,
          -2131.05747,
          -2131.08884,
          -2131.12137,
          -2131.15374,
          -2131.18438,
          -2131.21297,
          -2131.23805,
          -2131.25923,
          -2131.2751,
          -2131.28616,
          -2131.29121,
          -2131.28917,
          -2131.28099,
          -2131.26794,
          -2131.24932,
          -2131.22582,
          -2131.19927,
          -2131.16876,
          -2131.13768,
          -2131.10622,
          -2131.07468,
          -2131.04434,
          -2131.01643,
          -2130.99151,
          -2130.96923,
          -2130.95004,
          -2130.93422,
          -2130.92131,
          -2130.91166,
          -2130.90434,
          -2130.89924,
          -2130.89558,
          -2130.89335,
          -2130.89203,
          -2130.89138,
          -2130.89117,
          -2130.89151,
          -2130.89233,
          -2130.89415,
          -2130.89694,
          -2130.90135,
          -2130.90761,
          -2130.9162,
          -2130.92763,
          -2130.94179,
          -2130.95926,
          -2130.98002,
          -2131.00345,
          -2131.0303,
          -2131.05871,
          -2131.08863,
          -2131.11978,
          -2131.15103,
          -2131.18053,
          -2131.20814,
          -2131.23227,
          -2131.25272,
          -2131.26812,
          -2131.27889,
          -2131.28379,
          -2131.28179,
          -2131.27391,
          -2131.26096,
          -2131.24255,
          -2131.21906,
          -2131.19273,
          -2131.16209,
          -2131.13038,
          -2131.09822,
          -2131.06598,
          -2131.03483,
          -2131.00571,
          -2130.97949,
          -2130.95621,
          -2130.93624,
          -2130.91938,
          -2130.90573,
          -2130.89553,
          -2130.88781,
          -2130.88231,
          -2130.87829,
          -2130.87592,
          -2130.87433,
          -2130.87369,
          -2130.87342,
          -2130.87374,
          -2130.87465,
          -2130.8765,
          -2130.87942,
          -2130.88401,
          -2130.89075,
          -2130.89973,
          -2130.91218,
          -2130.92721,
          -2130.94575,
          -2130.96776,
          -2130.99281,
          -2131.02211,
          -2131.05271,
          -2131.08564,
          -2131.11954,
          -2131.1536,
          -2131.18647,
          -2131.21754,
          -2131.24506,
          -2131.26802,
          -2131.28518,
          -2131.29719,
          -2131.30271,
          -2131.30043,
          -2131.2915,
          -2131.27717,
          -2131.25671,
          -2131.23067,
          -2131.20138,
          -2131.16794,
          -2131.13355,
          -2131.0986,
          -2131.06407,
          -2131.03102,
          -2131.0002,
          -2130.97249,
          -2130.94789,
          -2130.92749,
          -2130.91027,
          -2130.89598,
          -2130.88507,
          -2130.87673,
          -2130.87101,
          -2130.86704,
          -2130.8645,
          -2130.86301,
          -2130.86227,
          -2130.86205,
          -2130.86252,
          -2130.86347,
          -2130.86556,
          -2130.86901,
          -2130.87412,
          -2130.88159,
          -2130.89102,
          -2130.90365,
          -2130.91896,
          -2130.93841,
          -2130.96198,
          -2130.98844,
          -2131.01844,
          -2131.0499,
          -2131.0835,
          -2131.11834,
          -2131.15292,
          -2131.18554,
          -2131.21565,
          -2131.24181,
          -2131.26372,
          -2131.28015,
          -2131.29154,
          -2131.29676,
          -2131.29462,
          -2131.28644,
          -2131.27322,
          -2131.25426,
          -2131.22992,
          -2131.20261,
          -2131.1714,
          -2131.1391,
          -2131.10621,
          -2131.07281,
          -2131.04034,
          -2131.01043,
          -2130.98297,
          -2130.95868,
          -2130.9372,
          -2130.91854,
          -2130.90337,
          -2130.89153,
          -2130.88304,
          -2130.87673,
          -2130.87196,
          -2130.86888,
          -2130.8668,
          -2130.8659,
          -2130.8656,
          -2130.86607,
          -2130.86725,
          -2130.86967,
          -2130.87315,
          -2130.87828,
          -2130.88495,
          -2130.89442,
          -2130.90661,
          -2130.92179,
          -2130.9406,
          -2130.96156,
          -2130.9849,
          -2131.01104,
          -2131.03856,
          -2131.06863,
          -2131.09906,
          -2131.12893,
          -2131.15697,
          -2131.18309,
          -2131.20654,
          -2131.22636,
          -2131.24138,
          -2131.25173,
          -2131.25646,
          -2131.25453,
          -2131.24672,
          -2131.23396,
          -2131.21555,
          -2131.19187,
          -2131.16558,
          -2131.13542,
          -2131.10419,
          -2131.07194,
          -2131.03934,
          -2131.00758,
          -2130.97888,
          -2130.95314,
          -2130.93,
          -2130.90941,
          -2130.89135,
          -2130.87693,
          -2130.86619,
          -2130.85872,
          -2130.85347,
          -2130.84923,
          -2130.84657,
          -2130.84484,
          -2130.84414,
          -2130.84394,
          -2130.84431,
          -2130.84537,
          -2130.84748,
          -2130.85054,
          -2130.85449,
          -2130.8598,
          -2130.86716,
          -2130.87779,
          -2130.89153,
          -2130.90869,
          -2130.92781,
          -2130.94931,
          -2130.97406,
          -2131.00077,
          -2131.03022,
          -2131.06028,
          -2131.09015,
          -2131.11824,
          -2131.14474,
          -2131.16897,
          -2131.18971,
          -2131.20521,
          -2131.2162,
          -2131.2211,
          -2131.21901,
          -2131.21087,
          -2131.19775,
          -2131.17868,
          -2131.15444,
          -2131.12747,
          -2131.09654,
          -2131.06425,
          -2131.03053,
          -2130.99668,
          -2130.96408,
          -2130.93426,
          -2130.90756,
          -2130.88334,
          -2130.86234,
          -2130.84452,
          -2130.8304,
          -2130.81948,
          -2130.81087,
          -2130.80464,
          -2130.79985,
          -2130.79698,
          -2130.79523,
          -2130.79446,
          -2130.7942,
          -2130.79458,
          -2130.79557,
          -2130.79815,
          -2130.80139,
          -2130.80627,
          -2130.81264,
          -2130.8216,
          -2130.83418,
          -2130.84929,
          -2130.86808,
          -2130.88951,
          -2130.91334,
          -2130.94116,
          -2130.97105,
          -2131.00314,
          -2131.03592,
          -2131.06859,
          -2131.09983,
          -2131.12849,
          -2131.15435,
          -2131.17606,
          -2131.19232,
          -2131.20381,
          -2131.20904,
          -2131.20679,
          -2131.19835,
          -2131.18445,
          -2131.16402,
          -2131.13821,
          -2131.10925,
          -2131.07569,
          -2131.0416,
          -2131.00709,
          -2130.97209,
          -2130.93832,
          -2130.90744,
          -2130.87982,
          -2130.85481,
          -2130.83358,
          -2130.816,
          -2130.80084,
          -2130.78965,
          -2130.78134,
          -2130.77571,
          -2130.77117,
          -2130.76847,
          -2130.76671,
          -2130.76579,
          -2130.76557,
          -2130.76598,
          -2130.76711,
          -2130.76932,
          -2130.77273,
          -2130.77768,
          -2130.78493,
          -2130.79445,
          -2130.80733,
          -2130.82282,
          -2130.84184,
          -2130.86477,
          -2130.89078,
          -2130.92019,
          -2130.951,
          -2130.98375,
          -2131.01738,
          -2131.05091,
          -2131.08261,
          -2131.11205,
          -2131.13802,
          -2131.16008,
          -2131.17644,
          -2131.18778,
          -2131.19283,
          -2131.1907,
          -2131.18237,
          -2131.16913,
          -2131.15011,
          -2131.12588,
          -2131.09884,
          -2131.06762,
          -2131.03605,
          -2131.00403,
          -2130.97203,
          -2130.94138,
          -2130.91319,
          -2130.88804,
          -2130.86531,
          -2130.84572,
          -2130.82939,
          -2130.81592,
          -2130.80554,
          -2130.79788,
          -2130.79255,
          -2130.78849,
          -2130.78591,
          -2130.78443,
          -2130.78371,
          -2130.78346,
          -2130.78393,
          -2130.7849,
          -2130.7871,
          -2130.79019,
          -2130.79495,
          -2130.80151,
          -2130.81014,
          -2130.82214,
          -2130.83645,
          -2130.85441,
          -2130.87539,
          -2130.89872,
          -2130.92594,
          -2130.95433,
          -2130.9839,
          -2131.01478,
          -2131.04618,
          -2131.07592,
          -2131.10339,
          -2131.12756,
          -2131.1483,
          -2131.16374,
          -2131.17446,
          -2131.17928,
          -2131.17731,
          -2131.16921,
          -2131.15638,
          -2131.13824,
          -2131.11533,
          -2131.08916,
          -2131.05877,
          -2131.02801,
          -2130.99676,
          -2130.96541,
          -2130.93442,
          -2130.90644,
          -2130.88086,
          -2130.8577,
          -2130.83753,
          -2130.82043,
          -2130.80691,
          -2130.79598,
          -2130.78763,
          -2130.78159,
          -2130.77736,
          -2130.77443,
          -2130.77266,
          -2130.77184,
          -2130.77154,
          -2130.77208,
          -2130.77296,
          -2130.77508,
          -2130.77853,
          -2130.78347,
          -2130.7904,
          -2130.79974,
          -2130.81195,
          -2130.82677,
          -2130.84524,
          -2130.86719,
          -2130.89147,
          -2130.91906,
          -2130.94887,
          -2130.98011,
          -2131.01248,
          -2131.04484,
          -2131.07609,
          -2131.10561,
          -2131.13137,
          -2131.15322,
          -2131.16939,
          -2131.18081,
          -2131.18599,
          -2131.18377,
          -2131.17536,
          -2131.16185,
          -2131.14253,
          -2131.11754,
          -2131.08919,
          -2131.0569,
          -2131.02356,
          -2130.98977,
          -2130.95529,
          -2130.92212,
          -2130.89117,
          -2130.86339,
          -2130.83862,
          -2130.81647,
          -2130.79813,
          -2130.78305,
          -2130.77188,
          -2130.76324,
          -2130.7565,
          -2130.75199,
          -2130.74888,
          -2130.74698,
          -2130.74607,
          -2130.74585,
          -2130.74629,
          -2130.74742,
          -2130.74964,
          -2130.75324,
          -2130.75878,
          -2130.76608,
          -2130.77587,
          -2130.78856,
          -2130.80476,
          -2130.82465,
          -2130.84876,
          -2130.87534,
          -2130.90542,
          -2130.93736,
          -2130.97173,
          -2131.00636,
          -2131.04151,
          -2131.07442,
          -2131.10527,
          -2131.13248,
          -2131.15519,
          -2131.17226,
          -2131.1841,
          -2131.18951,
          -2131.18722,
          -2131.17847,
          -2131.16459,
          -2131.14458,
          -2131.11877,
          -2131.0902,
          -2131.05702,
          -2131.02405,
          -2130.9899,
          -2130.95611,
          -2130.92309,
          -2130.89179,
          -2130.86474,
          -2130.83988,
          -2130.81884,
          -2130.80056,
          -2130.78548,
          -2130.77392,
          -2130.76521,
          -2130.75933,
          -2130.7549,
          -2130.75207,
          -2130.75025,
          -2130.74926,
          -2130.74904,
          -2130.74939,
          -2130.75045,
          -2130.75247,
          -2130.75596,
          -2130.76052,
          -2130.76744,
          -2130.77554,
          -2130.78809,
          -2130.80279,
          -2130.82153,
          -2130.84375,
          -2130.86787,
          -2130.89627,
          -2130.92526,
          -2130.95714,
          -2130.99074,
          -2131.024,
          -2131.05584,
          -2131.08603,
          -2131.11252,
          -2131.13585,
          -2131.15288,
          -2131.16508,
          -2131.1705,
          -2131.16822,
          -2131.1589,
          -2131.14424,
          -2131.12276,
          -2131.09548,
          -2131.04545,
          -2131.06881,
          -2131.09338,
          -2131.11949,
          -2131.14642,
          -2131.17316,
          -2131.19881,
          -2131.22257,
          -2131.24331,
          -2131.26095,
          -2131.27396,
          -2131.28305,
          -2131.28723,
          -2131.28552,
          -2131.27877,
          -2131.26805,
          -2131.25265,
          -2131.23291,
          -2131.21082,
          -2131.18521,
          -2131.15894,
          -2131.13211,
          -2131.10519,
          -2131.07926,
          -2131.055,
          -2131.033,
          -2131.0131,
          -2130.99575,
          -2130.98142,
          -2130.96943,
          -2130.96004,
          -2130.95303,
          -2130.94795,
          -2130.94437,
          -2130.94194,
          -2130.94038,
          -2130.93964,
          -2130.93942,
          -2130.93983,
          -2130.94085,
          -2130.94278,
          -2130.94578,
          -2130.95013,
          -2130.95622,
          -2130.96452,
          -2130.97506,
          -2130.988,
          -2131.00389,
          -2131.02259,
          -2131.04365,
          -2131.06747,
          -2131.09238,
          -2131.11906,
          -2131.14651,
          -2131.1739,
          -2131.19984,
          -2131.22401,
          -2131.24542,
          -2131.26332,
          -2131.27673,
          -2131.28605,
          -2131.29035,
          -2131.28855,
          -2131.28161,
          -2131.27046,
          -2131.25451,
          -2131.23409,
          -2131.21107,
          -2131.18451,
          -2131.15717,
          -2131.12913,
          -2131.10093,
          -2131.07349,
          -2131.04772,
          -2131.02418,
          -2131.00278,
          -2130.98417,
          -2130.96835,
          -2130.95543,
          -2130.94518,
          -2130.93731,
          -2130.93171,
          -2130.9275,
          -2130.92481,
          -2130.92301,
          -2130.92217,
          -2130.92193,
          -2130.92242,
          -2130.92351,
          -2130.92568,
          -2130.9291,
          -2130.934,
          -2130.94081,
          -2130.94984,
          -2130.96158,
          -2130.97591,
          -2130.99343,
          -2131.01422,
          -2131.03762,
          -2131.06418
         ],
         "yaxis": "y"
        },
        {
         "line": {
          "color": "red"
         },
         "name": "Detrended",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999
         ],
         "xaxis": "x",
         "y": [
          -0.029280485800427414,
          -0.05264050770801987,
          -0.07721052961505848,
          -0.1033105515225543,
          -0.13025057343020308,
          -0.1569905953374473,
          -0.1826406172449424,
          -0.20640063915243445,
          -0.22714066105982056,
          -0.24478068296775746,
          -0.2577907048753332,
          -0.2668807267828015,
          -0.27106074869016084,
          -0.2693507705976117,
          -0.26261079250525654,
          -0.25188081441274335,
          -0.23648083631996997,
          -0.21674085822769484,
          -0.19464088013501168,
          -0.16904090204252498,
          -0.1427709239496835,
          -0.11594094585734638,
          -0.08902096776500912,
          -0.06309098967221871,
          -0.03883101157953206,
          -0.016831033487051172,
          0.003068944605274737,
          0.02041892269789969,
          0.034748900789963955,
          0.046738878882479185,
          0.056118856974990194,
          0.06313883506754792,
          0.06821881316000145,
          0.07179879125260413,
          0.07422876934515443,
          0.07578874743785491,
          0.07652872553035195,
          0.07674870362279762,
          0.07633868171569702,
          0.07531865980809016,
          0.07338863790073447,
          0.0703886159931244,
          0.06603859408551216,
          0.059948572178200266,
          0.051648550270783744,
          0.04110852836311096,
          0.028168506456040632,
          0.012278484548005508,
          -0.006421537359528884,
          -0.027481559267016564,
          -0.051301581174357125,
          -0.07622160308164894,
          -0.10289162498929727,
          -0.13035164689654266,
          -0.15773166880399003,
          -0.18367169071188982,
          -0.20784171261902884,
          -0.2292417345265676,
          -0.24715175643405018,
          -0.2605617783415255,
          -0.26988180024909525,
          -0.27417182215640423,
          -0.2723818440640571,
          -0.2654418659712974,
          -0.2542918878789351,
          -0.23834190978641345,
          -0.21792193169403618,
          -0.19490195360140206,
          -0.16834197550906538,
          -0.14100199741642427,
          -0.11297201932393364,
          -0.08476204123144271,
          -0.05732206313905408,
          -0.03155208504631446,
          -0.008012106953628972,
          0.013387871139002527,
          0.03199784923117477,
          0.047817827323797246,
          0.06073780541646556,
          0.0709877835088264,
          0.07885776160173918,
          0.08444773969404196,
          0.08866771778684779,
          0.0913576958791964,
          0.09315767397174568,
          0.09399765206399024,
          0.09423763015638542,
          0.09374760824903206,
          0.09265758634137455,
          0.09048756443417005,
          0.0870675425267109,
          0.08216752061889565,
          0.0753574987115826,
          0.06632747680396278,
          0.054587454896591225,
          0.040257432989164954,
          0.02273741108183458,
          0.001947389174347336,
          -0.021452632733144128,
          -0.048012654640388064,
          -0.07579267654818977,
          -0.10540269845523653,
          -0.13581272036299197,
          -0.16620274227034315,
          -0.19514276417839937,
          -0.22203278608549226,
          -0.2457128079931863,
          -0.26578282990067237,
          -0.280672851808049,
          -0.2911028737153174,
          -0.29584289562308186,
          -0.29389291753022917,
          -0.2861129394377713,
          -0.27372296134535645,
          -0.2559129832529834,
          -0.2331430051604002,
          -0.20746302706766073,
          -0.17770304897521783,
          -0.14712307088257148,
          -0.11612309279007604,
          -0.08491311469742868,
          -0.05465313660488391,
          -0.026503158512241498,
          -0.0010131804197044403,
          0.02186679767237365,
          0.041886775764851336,
          0.05857675385732364,
          0.07232673194994277,
          0.08301671004255695,
          0.09101668813491415,
          0.09669666622767181,
          0.10082664432002275,
          0.10348662241267448,
          0.10514660050512248,
          0.10592657859751853,
          0.10615655669016633,
          0.10568653478276246,
          0.10465651287540823,
          0.10259649096769863,
          0.0994264690602904,
          0.09480644715313247,
          0.08795642524546565,
          0.07870640333794654,
          0.06659638142991753,
          0.05163635952249024,
          0.03324633761531004,
          0.011296315707568283,
          -0.013583706199824519,
          -0.041983728106970375,
          -0.07199375001437147,
          -0.10384377192212924,
          -0.1369537938294343,
          -0.16986381573678955,
          -0.2011638376443443,
          -0.2305438595517444,
          -0.2563738814592398,
          -0.27818390336688026,
          -0.29441392527405696,
          -0.3058439471815291,
          -0.31107396908919327,
          -0.3089339909965929,
          -0.300484012904235,
          -0.28690403481186877,
          -0.26742405671939196,
          -0.24249407862680528,
          -0.21464410053431493,
          -0.18220412244181716,
          -0.14917414434921739,
          -0.11556416625671773,
          -0.0818941881639148,
          -0.049674210071771085,
          -0.01947423197907483,
          0.007325746113565401,
          0.03159572420599943,
          0.05223570229873076,
          0.06926568039125414,
          0.08319565848387356,
          0.09353563657623454,
          0.10120561466874278,
          0.10661559276150001,
          0.11047557085385051,
          0.11287554894579443,
          0.11431552703834313,
          0.11497550513104215,
          0.11518548322374045,
          0.11482546131628624,
          0.11395543940852804,
          0.11224541750107164,
          0.109435395593664,
          0.10529537368620367,
          0.09885535177909333,
          0.09025532987152474,
          0.07865530796379971,
          0.06435528605652507,
          0.04636526414924447,
          0.024715242241654778,
          0.0002552203341110726,
          -0.027854801573084842,
          -0.05748482348053585,
          -0.08955484538819292,
          -0.12284486729595301,
          -0.1565348892036127,
          -0.18867491111086565,
          -0.21881493301862065,
          -0.24562495492591552,
          -0.2682549768333047,
          -0.2851949987407352,
          -0.29708502064841014,
          -0.3025250425557715,
          -0.3002750644632215,
          -0.29146508637040824,
          -0.27738510827794016,
          -0.25727513018546233,
          -0.23170515209312725,
          -0.20312517400043362,
          -0.17051519590768294,
          -0.13703521781553718,
          -0.10314523972283496,
          -0.06970526163013346,
          -0.03770528353834379,
          -0.008845305445447593,
          0.01776467264699022,
          0.04107465073957428,
          0.06120462883200162,
          0.07754460692467546,
          0.09090458501714238,
          0.10110456310985683,
          0.10862454120206166,
          0.11415451929497067,
          0.11799449738737167,
          0.12038447548002296,
          0.12180445357262215,
          0.12252443166516969,
          0.12274440975761536,
          0.12232438784985789,
          0.12133436594240266,
          0.11931434403504682,
          0.11623432212763873,
          0.11142430021982364,
          0.10459427831210633,
          0.09527425640499132,
          0.0834742344973165,
          0.06851421258988921,
          0.04959419068245552,
          0.027174168775218277,
          0.0016441468674202042,
          -0.026825875039776292,
          -0.05751589694727954,
          -0.08973591885478527,
          -0.12327594076214154,
          -0.15682596266969995,
          -0.18864598457730608,
          -0.2185360064845554,
          -0.24479602839210202,
          -0.26676605029933853,
          -0.28316607220676815,
          -0.29454609411459387,
          -0.29974611602210643,
          -0.2976161379297082,
          -0.28937615983704745,
          -0.2760961817448333,
          -0.25719620365225637,
          -0.23302622555956987,
          -0.2057962474668784,
          -0.1746262693745848,
          -0.1422962912820367,
          -0.10960631318948799,
          -0.07678633509704014,
          -0.04515635700408893,
          -0.015636378911949578,
          0.010943599180791352,
          0.03493357727347757,
          0.05580355536585557,
          0.07355353345838012,
          0.08809351155105105,
          0.0993734896433125,
          0.10787346773577156,
          0.1140234458280247,
          0.11849342392088147,
          0.12135340201348299,
          0.12326338010598192,
          0.12417335819827713,
          0.12442333629087443,
          0.12392331438331894,
          0.12276329247606554,
          0.12042327056860813,
          0.11684324866109819,
          0.11177322675348478,
          0.10447320484627198,
          0.09486318293875229,
          0.08218316103148027,
          0.06686313912359765,
          0.04813311721636637,
          0.02594309530877581,
          0.0014630734012825997,
          -0.026456948506620392,
          -0.055856970413969975,
          -0.08715699232152474,
          -0.1190970142288279,
          -0.15097703613628255,
          -0.18130705804378522,
          -0.20963707995133518,
          -0.23462710185867763,
          -0.2558671237661656,
          -0.2716471456733416,
          -0.28270716758106573,
          -0.2877871894884265,
          -0.2856772113959778,
          -0.2774672333034687,
          -0.2642772552107999,
          -0.245377277118223,
          -0.22114729902568797,
          -0.1940573209330978,
          -0.162537342840551,
          -0.13003736474865946,
          -0.09690738665585741,
          -0.06347740856335804,
          -0.031427430471012485,
          -0.001667452378114831,
          0.025132525714070653,
          0.049392503806757304,
          0.07043248189938822,
          0.08791245999191233,
          0.10255243808433079,
          0.11380241617689535,
          0.12229239426960703,
          0.12829237236201152,
          0.1324523504545141,
          0.1351023285469637,
          0.13679230663956332,
          0.13765228473221214,
          0.1378722628246578,
          0.13741224091745607,
          0.13630221900984907,
          0.13408219710208868,
          0.13071217519427591,
          0.12576215328681428,
          0.11875213137955143,
          0.10949210947228494,
          0.0970620875646091,
          0.08198206565703003,
          0.06343204374979905,
          0.04127202184236012,
          0.016441999935068452,
          -0.011758021972582355,
          -0.041308043880235346,
          -0.072678065787386,
          -0.10520808769479117,
          -0.1375781096026003,
          -0.16821813151000242,
          -0.1968081534173507,
          -0.2218881753246933,
          -0.24306819723233275,
          -0.2589382191399636,
          -0.26999824104768777,
          -0.2750482629548969,
          -0.27300828486249884,
          -0.26482830677014135,
          -0.2517783286775739,
          -0.23315835058474477,
          -0.20965837249241304,
          -0.18310839439982374,
          -0.15259841630722804,
          -0.12151843821447983,
          -0.09005846012223628,
          -0.05851848202973997,
          -0.028178503936942434,
          -0.0002685258446035732,
          0.024651452248235728,
          0.04693143034046443,
          0.0661214084329913,
          0.08194138652561378,
          0.09485136461762522,
          0.10450134271013667,
          0.11182132080284646,
          0.11692129889524949,
          0.12058127698810495,
          0.12281125508070545,
          0.12413123317310237,
          0.12478121126559927,
          0.12499118935829756,
          0.12465116745079285,
          0.12383114554313579,
          0.12201112363572975,
          0.1192211017282716,
          0.11481107982081085,
          0.10855105791324604,
          0.09996103600587958,
          0.08853101409840747,
          0.07437099219123411,
          0.05690097028355012,
          0.03614094837575976,
          0.012710926468116668,
          -0.01413909543907721,
          -0.04254911734642519,
          -0.07246913925428089,
          -0.10361916116153225,
          -0.13486918306898588,
          -0.16436920497653773,
          -0.19197922688408653,
          -0.21610924879132654,
          -0.2365592706987627,
          -0.25195929260644334,
          -0.2627293145137628,
          -0.2676293364211233,
          -0.2656293583286242,
          -0.25774938023596405,
          -0.24479940214359885,
          -0.22638942405092166,
          -0.2028994459583373,
          -0.1765694678665568,
          -0.1459294897736072,
          -0.11421951168131272,
          -0.08205953358856277,
          -0.0498195554960148,
          -0.0186695774036707,
          0.010450400689023809,
          0.03667037878130941,
          0.059950356874196586,
          0.07992033496657314,
          0.09678031305929835,
          0.11043029115171521,
          0.12063026924442966,
          0.1283502473365843,
          0.13385022542934166,
          0.13787020352174295,
          0.14024018161444474,
          0.1418301597068421,
          0.1424701377995916,
          0.14274011589168367,
          0.14242009398412847,
          0.14151007207647126,
          0.13966005016936833,
          0.1367400282615563,
          0.13215000635409524,
          0.12540998444683282,
          0.11642996253931415,
          0.10397994063214355,
          0.08894991872466562,
          0.07040989681718202,
          0.048399874909591745,
          0.02334985300194603,
          -0.005950168905201281,
          -0.036550190812704386,
          -0.06948021272000915,
          -0.10338023462782076,
          -0.1374402565352284,
          -0.17031027844268465,
          -0.20138030035059273,
          -0.2289003222581414,
          -0.2518603441653795,
          -0.2690203660727093,
          -0.2810303879800813,
          -0.2865504098876954,
          -0.2842704317949938,
          -0.2753404537024835,
          -0.2610104756099645,
          -0.2405504975176882,
          -0.21451051942494814,
          -0.18522054133245547,
          -0.15178056323975397,
          -0.11739058514740464,
          -0.08244060705465017,
          -0.04791062896219955,
          -0.014860650869650271,
          0.015959327222844877,
          0.04366930531523394,
          0.06826928340751692,
          0.0886692614999447,
          0.10588923959267049,
          0.1201792176852905,
          0.13108919577780398,
          0.13942917387021225,
          0.14514915196286893,
          0.14911913005516908,
          0.15165910814766903,
          0.15314908624031887,
          0.1538890643328159,
          0.15410904242526158,
          0.15363902051785772,
          0.15268899861075624,
          0.15059897670289502,
          0.14714895479573897,
          0.14203893288822655,
          0.13456891098076085,
          0.12513888907324144,
          0.11250886716516106,
          0.09719884525793532,
          0.07774882335024813,
          0.0541788014429585,
          0.02771877953546209,
          -0.00228124237173688,
          -0.03374126427934243,
          -0.06734128618700197,
          -0.1021813080942593,
          -0.1367613300017183,
          -0.16938135190912362,
          -0.199491373816727,
          -0.22565139572407134,
          -0.24756141763145934,
          -0.2639914395390406,
          -0.2753814614466137,
          -0.28060148335407575,
          -0.2784615052614754,
          -0.27028152716866316,
          -0.25706154907675227,
          -0.23810157098432683,
          -0.21376159289184216,
          -0.18645161479889794,
          -0.15524163670670532,
          -0.12294165861385409,
          -0.09005168052135559,
          -0.056651702429007855,
          -0.024181724336358457,
          0.005728253756387858,
          0.03318823184872599,
          0.057478209941109526,
          0.07895818803399379,
          0.09761816612626717,
          0.11278814421893912,
          0.1246281223116057,
          0.13311810040386263,
          0.1394280784966213,
          0.1441980565891754,
          0.14727803468122147,
          0.14935801277397331,
          0.15025799086652114,
          0.15055796895876483,
          0.15008794705136097,
          0.14890792514415807,
          0.1464879032364479,
          0.14300788132914022,
          0.1378778594216783,
          0.13120783751401177,
          0.12173781560659336,
          0.10954779369922107,
          0.09436777179189448,
          0.07555774988441044,
          0.054597727976670285,
          0.03125770606948208,
          0.005117684162087244,
          -0.02240233774546141,
          -0.05247235965316577,
          -0.08290238156041596,
          -0.11277240346817052,
          -0.14081242537577054,
          -0.16693244728321588,
          -0.19038246919080848,
          -0.21020249109824363,
          -0.22522251300551943,
          -0.2355725349129898,
          -0.24030255682055213,
          -0.2383725787281037,
          -0.23056260063549416,
          -0.21780262254287663,
          -0.19939264445019944,
          -0.17571266635786742,
          -0.14942268826507643,
          -0.11926271017273393,
          -0.08803273208013707,
          -0.05578275398738697,
          -0.023182775894838414,
          0.008577202197557199,
          0.03727718028949312,
          0.0630171583820811,
          0.086157136474867,
          0.10674711456704244,
          0.12480709265992118,
          0.13922707075244034,
          0.1499670488447009,
          0.15743702693725936,
          0.1626870050299658,
          0.16692698312272114,
          0.16958696121491812,
          0.17131693930741676,
          0.1720169174000148,
          0.17221689549251096,
          0.17184687358530937,
          0.1707868516778035,
          0.1686768297704475,
          0.16561680786298894,
          0.16166678595527628,
          0.15635676404735932,
          0.148996742140298,
          0.13836672023262508,
          0.12462669832530082,
          0.10746667641751628,
          0.0883466545101328,
          0.06684663260284651,
          0.042096610695352865,
          0.015386588787805522,
          -0.014063433119645197,
          -0.04412345502714743,
          -0.07399347693444724,
          -0.10208349884169365,
          -0.12858352074954382,
          -0.1528135426569861,
          -0.1735535645643722,
          -0.18905358647180037,
          -0.20004360837901913,
          -0.20494363028683438,
          -0.20285365219433515,
          -0.19471367410187668,
          -0.18159369600925857,
          -0.16252371791688347,
          -0.13828373982414632,
          -0.11131376173170793,
          -0.08038378363926313,
          -0.04809380554661402,
          -0.014373827454164712,
          0.019476150638183753,
          0.05207612873073231,
          0.08189610682347848,
          0.10859608491591644,
          0.13281606300870408,
          0.15381604110098124,
          0.17163601919355642,
          0.18575599728637826,
          0.19667597537863912,
          0.20528595347150258,
          0.21151593156355375,
          0.21630590965605734,
          0.21917588774840624,
          0.22092586584085439,
          0.22169584393350306,
          0.22195582202630249,
          0.22157580011844402,
          0.2205857782109888,
          0.21800575630368257,
          0.2147657343962237,
          0.20988571248881271,
          0.20351569058129826,
          0.1945556686737291,
          0.18197564676665934,
          0.16686562485892864,
          0.1480756029513941,
          0.12664558104415846,
          0.10281555913661578,
          0.0749955372293698,
          0.04510551532121099,
          0.013015493414059165,
          -0.019764528493396938,
          -0.05243455040090339,
          -0.08367457230860964,
          -0.11233459421600855,
          -0.13819461612320083,
          -0.15990463803063903,
          -0.17616465993842212,
          -0.18765468184574274,
          -0.19288470375340694,
          -0.19063472566085693,
          -0.18219474756824638,
          -0.1682947694757786,
          -0.1478647913831992,
          -0.12205481329056056,
          -0.09309483519791684,
          -0.05953485710551831,
          -0.025444879012866295,
          0.009065099079180072,
          0.044065077171580924,
          0.07783505526413137,
          0.10871503335692978,
          0.1363350114493187,
          0.16134498954215815,
          0.18257496763453673,
          0.2001549457272631,
          0.21531492381973294,
          0.22650490191199424,
          0.23481488000470563,
          0.24044485809736216,
          0.24498483618981481,
          0.24768481428236555,
          0.24944479237501582,
          0.25036477046751315,
          0.2505847485599588,
          0.2501747266524035,
          0.24904470474530171,
          0.2468346828372887,
          0.24342466092957693,
          0.2384746390221153,
          0.23122461711500364,
          0.2217045952074841,
          0.20882457329980753,
          0.1933345513925815,
          0.17431452948494552,
          0.1513845075774043,
          0.1253744856699086,
          0.09596446376281165,
          0.06515444185515662,
          0.03240441994785215,
          -0.0012256019595042744,
          -0.03475562386711317,
          -0.06645564577456753,
          -0.09589566768227087,
          -0.1218656895894128,
          -0.1439257114971042,
          -0.16028573340508956,
          -0.17162575531256152,
          -0.17667577721977068,
          -0.17454579912737245,
          -0.16621582103471155,
          -0.1529758429423964,
          -0.1339558648496677,
          -0.10972588675713268,
          -0.08268590866464365,
          -0.05146593057179416,
          -0.019895952479600965,
          0.012124025613047706,
          0.04412400370574687,
          0.07477398179798911,
          0.10296395989053053,
          0.12811393798347126,
          0.1508439160757007,
          0.1704338941685819,
          0.18676387226105362,
          0.20023385035301544,
          0.21061382844573018,
          0.2182738065380363,
          0.22360378463054076,
          0.2276637627232958,
          0.23024374081569476,
          0.23172371890814247,
          0.23244369700069,
          0.2326936750932873,
          0.23222365318588345,
          0.23125363127837772,
          0.2290536093710216,
          0.2259635874634114,
          0.22120356555615217,
          0.21464354364889005,
          0.20601352174116982,
          0.1940134998335452,
          0.1797034779265232,
          0.16174345601893947,
          0.14076343411079506,
          0.11743341220335424,
          0.09021339029595765,
          0.061823368388559174,
          0.03225334648095668,
          0.0013733245737057587,
          -0.03002669733359653,
          -0.05976671924145194,
          -0.08723674114889945,
          -0.11140676305603847,
          -0.13214678496342458,
          -0.14758680687100423,
          -0.1583068287786773,
          -0.16312685068578503,
          -0.16115687259343758,
          -0.15305689450087812,
          -0.14022691640820995,
          -0.12208693831598794,
          -0.09917696022330347,
          -0.073006982131119,
          -0.04261700403867508,
          -0.011857025946028443,
          0.019392952146517928,
          0.05074293023926657,
          0.08173290833155988,
          0.10971288642394939,
          0.1352928645164866,
          0.158452842609222,
          0.17862282070200308,
          0.19572279879412235,
          0.2092427768870948,
          0.2201727549795578,
          0.2285227330721682,
          0.2345627111644717,
          0.2387926892570249,
          0.24172266734967707,
          0.24349264544207472,
          0.24431262353482452,
          0.24461260162706822,
          0.24407257971915897,
          0.24319255781210813,
          0.24107253590455002,
          0.23762251399693923,
          0.23268249208967973,
          0.2257524701822149,
          0.21641244827469563,
          0.20420242636737385,
          0.1893824044595931,
          0.17091238255216012,
          0.14896236064487312,
          0.1246823387373297,
          0.09709231682973041,
          0.0672822949222791,
          0.036042273015027604,
          0.003672251107673219,
          -0.028687770799933787,
          -0.059937792707387416,
          -0.08945781461488878,
          -0.11521783652278828,
          -0.13706785843032776,
          -0.15323788033765595,
          -0.16465790224492594,
          -0.169837924152489,
          -0.16761794606009062,
          -0.1592079679676317,
          -0.14569798987486138,
          -0.12637801178243535,
          -0.10138803369000016,
          -0.07303805559740795,
          -0.04074807750475884,
          -0.007408099412259617,
          0.026381878680240334,
          0.060861856773044565,
          0.09403183486529088,
          0.12498181295813993,
          0.15276179105057963,
          0.17753176914311553,
          0.19968174723499033,
          0.21802172532761688,
          0.2331017034202887,
          0.24427168151305523,
          0.2529116596051608,
          0.2596516376979707,
          0.26416161579027175,
          0.2672715938829242,
          0.26917157197567576,
          0.27008155006797097,
          0.2703015281608714,
          0.2698615062531644,
          0.2687314843456079,
          0.26651146243830226,
          0.2629114405308428,
          0.25737141862327917,
          0.2500713967160664,
          0.2402813748085464,
          0.22759135290107224,
          0.21139133099313767,
          0.19150130908565188,
          0.16739128717836138,
          0.1408112652707132,
          0.11073124336326146,
          0.0787912214559583,
          0.044421199548196455,
          0.009791177641091053,
          -0.025358844266520464,
          -0.05826886617387572,
          -0.08911888808142976,
          -0.11632890998907897,
          -0.13903893189626615,
          -0.1561089538035958,
          -0.16794897571116962,
          -0.1733589976188341,
          -0.17106901952593034,
          -0.16231904143342035,
          -0.14843906334090207,
          -0.12842908524908125,
          -0.10261910715644262,
          -0.07404912906395111,
          -0.04086915097150268,
          -0.007899172878751415,
          0.026250805213749118,
          0.06004078330624907,
          0.09306076139910147,
          0.12436073949129423,
          0.1514107175839854,
          0.17627069567652143,
          0.19731067376915234,
          0.21559065186147564,
          0.23067062995414744,
          0.24223060804661145,
          0.25094058613922243,
          0.2568205642319299,
          0.2612505423244329,
          0.2640805204168828,
          0.26590049850892683,
          0.2668904766014748,
          0.2671104546939205,
          0.2667604327866684,
          0.2657004108791625,
          0.2636803889718067,
          0.2601903670642969,
          0.25563034515698746,
          0.24871032324927,
          0.24061030134180328,
          0.2280602794344304,
          0.21336025752680143,
          0.19462023561936803,
          0.17240021371208059,
          0.14828019180458796,
          0.11988016989698735,
          0.09089014798973949,
          0.05901012608228484,
          0.025410104174625303,
          -0.007849917732983158,
          -0.039689939640538796,
          -0.06987996154794018,
          -0.09636998345558823,
          -0.11970000536302905,
          -0.1367300272704597,
          -0.1489300491780341,
          -0.15435007108544596,
          -0.15207009299274432,
          -0.14275011490008183,
          -0.12809013680771386,
          -0.10661015871528434,
          -0.07933018062249175,
          -0.0293002025300666,
          -0.05266022443765905,
          -0.07723024634469766,
          -0.10334026825239562,
          -0.13027029015984226,
          -0.1570103120670865,
          -0.18266033397503634,
          -0.20642035588252838,
          -0.2271603777899145,
          -0.24480039969739664,
          -0.25781042160497236,
          -0.2669004435124407,
          -0.2710804654198,
          -0.2693704873272509,
          -0.2626205092346936,
          -0.25190053114238253,
          -0.23650055304960915,
          -0.21676057495733403,
          -0.19467059686439825,
          -0.16906061877216416,
          -0.14279064067932268,
          -0.11596066258698556,
          -0.0890406844946483,
          -0.0631107064018579,
          -0.038850728309171245,
          -0.016850750217145105,
          0.0030492278751808044,
          0.020399205967805756,
          0.03472918406032477,
          0.04671916215284,
          0.056109140245553135,
          0.06311911833790873,
          0.06819909643036226,
          0.07177907452296495,
          0.07420905261551525,
          0.07576903070821572,
          0.07650900880071276,
          0.07672898689315844,
          0.07631896498605784,
          0.07529894307845098,
          0.07336892117109528,
          0.07036889926348522,
          0.06601887735587297,
          0.05992885544856108,
          0.05162883354068981,
          0.04108881163301703,
          0.0281487897259467,
          0.012258767818366323,
          -0.006441254089168069,
          -0.02750127599665575,
          -0.05132129790399631,
          -0.07623131981154074,
          -0.10291134171893646,
          -0.13036136362643447,
          -0.15775138553362922,
          -0.183691407441529,
          -0.20786142934866803,
          -0.2292714512564089,
          -0.24717147316368937,
          -0.2605814950711647,
          -0.26990151697873443,
          -0.27420153888624554,
          -0.27240156079369626,
          -0.2654615827013913,
          -0.254311604609029,
          -0.23836162651650739,
          -0.21794164842367536,
          -0.19492167033104124,
          -0.16836169223870456,
          -0.14102171414606346,
          -0.1129817360533707,
          -0.0847817579610819,
          -0.057341779868693266,
          -0.031571801775953645,
          -0.008031823683268158,
          0.013368154409363342,
          0.03197813250153558,
          0.04779811059415806,
          0.06071808868682638,
          0.07096806677918721,
          0.0788380448721,
          0.0844380229646049,
          0.0886480010572086,
          0.09133797914910247,
          0.09313795724165175,
          0.09397793533435106,
          0.09421791342674624,
          0.09372789151939287,
          0.09263786961173537,
          0.09046784770453087,
          0.08704782579707171,
          0.08214780388925647,
          0.07533778198194341,
          0.0663077600743236,
          0.05456773816695204,
          0.04023771625952577,
          0.022717694352195394,
          0.0019276724447081506,
          -0.021472349462783313,
          -0.04803237137002725
         ],
         "yaxis": "y"
        },
        {
         "mode": "lines+markers",
         "name": "Power Spectrum",
         "type": "scatter",
         "x": [
          0.000011111111111111112,
          0.000022222222222222223,
          0.000033333333333333335,
          0.000044444444444444447,
          0.00005555555555555556,
          0.00006666666666666667,
          0.00007777777777777778,
          0.00008888888888888889,
          0.0001,
          0.00011111111111111112,
          0.00012222222222222224,
          0.00013333333333333334,
          0.00014444444444444444,
          0.00015555555555555556,
          0.0001666666666666667,
          0.00017777777777777779,
          0.00018888888888888888,
          0.0002,
          0.00021111111111111113,
          0.00022222222222222223,
          0.00023333333333333333,
          0.0002444444444444445,
          0.0002555555555555556,
          0.0002666666666666667,
          0.0002777777777777778,
          0.0002888888888888889,
          0.00030000000000000003,
          0.0003111111111111111,
          0.0003222222222222222,
          0.0003333333333333334,
          0.0003444444444444445,
          0.00035555555555555557,
          0.00036666666666666667,
          0.00037777777777777777,
          0.0003888888888888889,
          0.0004,
          0.0004111111111111111,
          0.00042222222222222227,
          0.00043333333333333337,
          0.00044444444444444447,
          0.00045555555555555556,
          0.00046666666666666666,
          0.0004777777777777778,
          0.000488888888888889,
          0.0005,
          0.0005111111111111112,
          0.0005222222222222222,
          0.0005333333333333334,
          0.0005444444444444445,
          0.0005555555555555556
         ],
         "xaxis": "x2",
         "y": [
          27.493785787228784,
          13.747684654964797,
          9.164528330735653,
          6.874528183017928,
          5.500106111306856,
          4.581927774151348,
          3.9275933908161633,
          3.436685758633602,
          3.054258616833798,
          2.7494549038649128,
          2.5000907368089407,
          2.292003696391292,
          2.116428186799334,
          1.964338286015568,
          1.8340117868108319,
          1.7195125741889339,
          1.6172232678376028,
          1.528461355617034,
          1.4481342247595037,
          1.375204808555024,
          1.3101824456331996,
          1.2503154833373786,
          1.1962840305822169,
          1.1456450183762956,
          1.1012241272272447,
          1.0580168573450435,
          1.0193381758699152,
          0.9830471440517099,
          0.9487692854836467,
          0.917830764101076,
          0.8883868665073101,
          0.8595688683711137,
          0.8335738144364769,
          0.8089179868827003,
          0.786193400503288,
          0.7632840629630152,
          0.7441557953757474,
          0.7239454419898038,
          0.7062906665153779,
          0.6881969532830368,
          0.6717257028407467,
          0.6560439535237456,
          0.6392936646204362,
          0.6264805449343455,
          0.6127541157715222,
          0.599427896890553,
          0.5852503264976572,
          0.5741416761026209,
          0.5623587947618132,
          0.5516357404259314
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Semnal Original vs Detrended",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Power Spectrum (FFT)",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 800,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "AnalizƒÉ FFT - Energie TotalƒÉ"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Timp (pa»ôi)"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Frecven»õa (Hz)"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.625,
          1
         ],
         "title": {
          "text": "Energie"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          0.375
         ],
         "title": {
          "text": "Amplitudine"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåä Creare 3 features Fourier...\n",
      "‚úÖ Features Fourier create: ['sin_f1_0.0200Hz', 'cos_f1_0.0200Hz', 'sin_f2_0.0211Hz', 'cos_f2_0.0211Hz', 'sin_f3_0.0011Hz', 'cos_f3_0.0011Hz']\n",
      "üìè Shape features Fourier: (90000, 6)\n",
      "üîß Creare features comprehensive...\n",
      "‚úÖ Total features: 18\n",
      "üìã Feature names: ['Energy_scaled', 'Temp_scaled', 'Pressure_scaled', 'Energy_velocity', 'Energy_acceleration', 'Energy_MA5', 'Energy_MA10', 'Energy_MA20', 'Energy_Vol5', 'Energy_Vol10', 'Temp_velocity', 'Temp_MA10', 'sin_f1_0.0200Hz', 'cos_f1_0.0200Hz', 'sin_f2_0.0211Hz', 'cos_f2_0.0211Hz', 'sin_f3_0.0011Hz', 'cos_f3_0.0011Hz']\n",
      "\n",
      "üîç Verificare calitatea features:\n",
      "NaN values: 0\n",
      "Inf values: 0\n",
      "Feature range: [-4.3568, 3.8736]\n",
      "üîß Creare secven»õe cu parametri:\n",
      "   - Sequence length: 100\n",
      "   - Output steps: 25\n",
      "   - Overlap ratio: 0.7\n",
      "‚úÖ Secven»õe create:\n",
      "   - Input shape: (2996, 100, 18)\n",
      "   - Target shape: (2996, 25)\n",
      "   - Total samples: 2996\n",
      "üèóÔ∏è Construire model LSTM pentru:\n",
      "   - Input shape: (100, 18)\n",
      "   - Output steps: 25\n",
      "   - Dropout rate: 0.3\n",
      "‚úÖ Model construit cu succes!\n",
      "üìä Parametri totali: 342,297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 11:21:28.352487: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2025-08-11 11:21:28.352733: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:135] retrieving CUDA diagnostic information for host: hondar\n",
      "2025-08-11 11:21:28.352745: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:142] hostname: hondar\n",
      "2025-08-11 11:21:28.352881: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:166] libcuda reported version is: 535.247.1\n",
      "2025-08-11 11:21:28.352897: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:170] kernel reported version is: 535.247.1\n",
      "2025-08-11 11:21:28.352901: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:249] kernel version seems to match DSO: 535.247.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ bidirectional_lstm_1            ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       ‚îÇ       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,528</span> ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 ‚îÇ                        ‚îÇ               ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ batch_norm_1                    ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ bidirectional_lstm_2            ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       ‚îÇ       <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 ‚îÇ                        ‚îÇ               ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ batch_norm_2                    ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lstm_final (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)               ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             ‚îÇ        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,608</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ batch_norm_3                    ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">425</span> ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ bidirectional_lstm_1            ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       ‚îÇ       \u001b[38;5;34m150,528\u001b[0m ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mBidirectional\u001b[0m)                 ‚îÇ                        ‚îÇ               ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ batch_norm_1                    ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       ‚îÇ         \u001b[38;5;34m1,024\u001b[0m ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ bidirectional_lstm_2            ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       ‚îÇ       \u001b[38;5;34m164,352\u001b[0m ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mBidirectional\u001b[0m)                 ‚îÇ                        ‚îÇ               ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ batch_norm_2                    ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       ‚îÇ           \u001b[38;5;34m512\u001b[0m ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lstm_final (\u001b[38;5;33mLSTM\u001b[0m)               ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             ‚îÇ        \u001b[38;5;34m20,608\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ batch_norm_3                    ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             ‚îÇ           \u001b[38;5;34m128\u001b[0m ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             ‚îÇ         \u001b[38;5;34m2,112\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             ‚îÇ         \u001b[38;5;34m2,080\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             ‚îÇ           \u001b[38;5;34m528\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ output (\u001b[38;5;33mDense\u001b[0m)                  ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)             ‚îÇ           \u001b[38;5;34m425\u001b[0m ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">342,297</span> (1.31 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m342,297\u001b[0m (1.31 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">341,465</span> (1.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m341,465\u001b[0m (1.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> (3.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m832\u001b[0m (3.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä √émpƒÉr»õirea datelor:\n",
      "   - Train samples: 2396\n",
      "   - Test samples: 600\n",
      "   - Features per sample: 18\n",
      "   - Sequence length: 100\n",
      "üöÄ √éncepe antrenarea...\n",
      "Epoch 1/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.4721 - mae: 0.8749 - mape: 152.0317 - mse: 1.0656\n",
      "Epoch 1: val_loss improved from inf to 0.42202, saving model to best_energy_lstm_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m75/75\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 122ms/step - loss: 0.4718 - mae: 0.8746 - mape: 151.8707 - mse: 1.0649 - val_loss: 0.4220 - val_mae: 0.8273 - val_mape: 102.9648 - val_mse: 0.9163 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m64/75\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.3850 - mae: 0.7639 - mape: 132.0340 - mse: 0.8471"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 446\u001b[39m\n\u001b[32m    442\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müöÄ √éncepe antrenarea...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    444\u001b[39m \u001b[38;5;66;03m# %% \u001b[39;00m\n\u001b[32m    445\u001b[39m \u001b[38;5;66;03m# Antrenare model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m446\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    448\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    449\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    450\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    452\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m    453\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Antrenarea completatƒÉ!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    457\u001b[39m \u001b[38;5;66;03m# %% [markdown]\u001b[39;00m\n\u001b[32m    458\u001b[39m \u001b[38;5;66;03m# ## 9. Evaluarea Modelului\u001b[39;00m\n\u001b[32m    459\u001b[39m \n\u001b[32m    460\u001b[39m \u001b[38;5;66;03m# %%\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf216/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf216/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf216/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf216/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf216/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf216/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf216/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf216/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf216/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf216/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf216/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1552\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1550\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1551\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1552\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1553\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1554\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1555\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1556\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1557\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1558\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1560\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1561\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1562\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1566\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1567\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf216/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # AnalizƒÉ Time Series - Energie CineticƒÉ Pentilfuran cu FFT\n",
    "# \n",
    "# Acest notebook analizeazƒÉ datele de energie cineticƒÉ pentru molecula de pentilfuran √Æntr-un c√¢mp electric.\n",
    "# Folosim transformata Fourier pentru a exploata natura sinusoidalƒÉ a datelor.\n",
    "# \n",
    "# **Parametri cunoscu»õi:**\n",
    "# - Frecven»õa dominantƒÉ: 0.020000 Hz\n",
    "# - Perioada principalƒÉ: 50.00 pa»ôi de timp\n",
    "# - Window size recomandat: 100 pa»ôi\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1. Import Libraries »ôi Configurare\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as sp\n",
    "from scipy import signal\n",
    "from scipy.fft import fft, fftfreq, ifft\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurare pentru reproducibilitate\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"üì¶ Libraries importate cu succes!\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. √éncƒÉrcarea »ôi Preprocesarea Datelor\n",
    "\n",
    "# %%\n",
    "# √éncƒÉrcare date\n",
    "my_file = \"./pentilfuran.MDE\"\n",
    "\n",
    "df = pd.read_csv(\n",
    "    my_file,\n",
    "    sep=r\"\\s+\",\n",
    "    comment='#',\n",
    "    names=[\"Step\", \"T\", \"E_KS\", \"E_tot\", \"Vol\", \"P\"]\n",
    ")\n",
    "\n",
    "print(f\"üìä Dimensiune date originale: {df.shape}\")\n",
    "print(f\"üìã Coloane disponibile: {df.columns.tolist()}\")\n",
    "print(f\"üî¢ NumƒÉrul de steps unici: {df['Step'].nunique()}\")\n",
    "\n",
    "# %%\n",
    "# Selectare liniile 1:901 pentru fiecare Step (optimizat)\n",
    "df_data = (\n",
    "    df.groupby(\"Step\", group_keys=False)\n",
    "    .apply(lambda g: g.iloc[1:901])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Dimensiunea dupƒÉ filtrare: {len(df_data)} r√¢nduri\")\n",
    "print(f\"üìà Range energie totalƒÉ: [{df_data['E_tot'].min():.6f}, {df_data['E_tot'].max():.6f}]\")\n",
    "print(f\"üå°Ô∏è Range temperaturƒÉ: [{df_data['T'].min():.4f}, {df_data['T'].max():.4f}]\")\n",
    "\n",
    "# Verificare pentru valori lipsƒÉ\n",
    "print(f\"\\nüîç Valori lipsƒÉ per coloanƒÉ:\")\n",
    "print(df_data.isnull().sum())\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. Analiza PeriodicitƒÉ»õii cu FFT\n",
    "\n",
    "# %%\n",
    "def analyze_periodicity(signal_data, sampling_rate=1.0, plot=True):\n",
    "    \"\"\"AnalizƒÉ avansatƒÉ de periodicitate cu FFT\"\"\"\n",
    "    print(\"üîç AnalizƒÉ periodicitate cu FFT...\")\n",
    "    \n",
    "    # Remove trend pentru FFT mai precisƒÉ\n",
    "    detrended_signal = signal.detrend(signal_data)\n",
    "    \n",
    "    # FFT\n",
    "    fft_values = fft(detrended_signal)\n",
    "    frequencies = fftfreq(len(signal_data), d=1/sampling_rate)\n",
    "    \n",
    "    # Power spectrum (doar frecven»õele pozitive, fƒÉrƒÉ DC)\n",
    "    power_spectrum = np.abs(fft_values[1:len(signal_data)//2])\n",
    "    freqs_positive = frequencies[1:len(signal_data)//2]\n",
    "    \n",
    "    # Top 10 frecven»õe dominante\n",
    "    dominant_indices = np.argsort(power_spectrum)[-10:][::-1]\n",
    "    dominant_freqs = freqs_positive[dominant_indices]\n",
    "    dominant_powers = power_spectrum[dominant_indices]\n",
    "    \n",
    "    print(f\"üéØ Top 10 frecven»õe dominante:\")\n",
    "    for i, (freq, power) in enumerate(zip(dominant_freqs, dominant_powers)):\n",
    "        period = 1/freq if freq != 0 else np.inf\n",
    "        print(f\"   {i+1:2d}. Freq: {freq:.6f} Hz, PerioadƒÉ: {period:8.2f} pa»ôi, Putere: {power:.2e}\")\n",
    "    \n",
    "    if plot:\n",
    "        # Plot FFT\n",
    "        fig = sp.make_subplots(\n",
    "            rows=2, cols=1,\n",
    "            subplot_titles=['Semnal Original vs Detrended', 'Power Spectrum (FFT)']\n",
    "        )\n",
    "        \n",
    "        # Semnal original vs detrended (primele 1000 puncte pentru vizibilitate)\n",
    "        sample_size = min(1000, len(signal_data))\n",
    "        x_axis = np.arange(sample_size)\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=x_axis, y=signal_data[:sample_size], \n",
    "                      name='Original', line=dict(color='blue')),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=x_axis, y=detrended_signal[:sample_size], \n",
    "                      name='Detrended', line=dict(color='red')),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # Power spectrum (zoom pe primele 50 frecven»õe pentru claritate)\n",
    "        freq_limit = min(50, len(freqs_positive))\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=freqs_positive[:freq_limit], y=power_spectrum[:freq_limit],\n",
    "                      mode='lines+markers', name='Power Spectrum'),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        # Eviden»õiazƒÉ frecven»õele dominante\n",
    "        for i, (freq, power) in enumerate(zip(dominant_freqs[:5], dominant_powers[:5])):\n",
    "            if freq <= freqs_positive[freq_limit-1]:  # Doar dacƒÉ e √Æn range-ul vizualizat\n",
    "                fig.add_vline(x=freq, line_dash=\"dash\", \n",
    "                             annotation_text=f\"f{i+1}={freq:.4f}Hz\", \n",
    "                             row=2, col=1)\n",
    "        \n",
    "        fig.update_layout(height=800, title_text=\"AnalizƒÉ FFT - Energie TotalƒÉ\")\n",
    "        fig.update_xaxes(title_text=\"Timp (pa»ôi)\", row=1, col=1)\n",
    "        fig.update_xaxes(title_text=\"Frecven»õa (Hz)\", row=2, col=1)\n",
    "        fig.update_yaxes(title_text=\"Energie\", row=1, col=1)\n",
    "        fig.update_yaxes(title_text=\"Amplitudine\", row=2, col=1)\n",
    "        fig.show()\n",
    "    \n",
    "    return dominant_freqs, power_spectrum, frequencies, detrended_signal\n",
    "\n",
    "# Rulare analizƒÉ FFT pe energia totalƒÉ\n",
    "energy_data = df_data['E_tot'].values\n",
    "dominant_freqs, power_spectrum, frequencies, detrended_energy = analyze_periodicity(energy_data)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4. Crearea Features Fourier\n",
    "\n",
    "# %%\n",
    "def create_fourier_features(data, dominant_freqs, top_n=5):\n",
    "    \"\"\"CreeazƒÉ features bazate pe componentele Fourier dominante\"\"\"\n",
    "    print(f\"üåä Creare {top_n} features Fourier...\")\n",
    "    \n",
    "    fourier_features = []\n",
    "    feature_names = []\n",
    "    \n",
    "    t = np.arange(len(data))\n",
    "    \n",
    "    for i, freq in enumerate(dominant_freqs[:top_n]):\n",
    "        # Sin »ôi Cos pentru fiecare frecven»õƒÉ dominantƒÉ\n",
    "        sin_component = np.sin(2 * np.pi * freq * t)\n",
    "        cos_component = np.cos(2 * np.pi * freq * t)\n",
    "        \n",
    "        fourier_features.extend([sin_component, cos_component])\n",
    "        feature_names.extend([f'sin_f{i+1}_{freq:.4f}Hz', f'cos_f{i+1}_{freq:.4f}Hz'])\n",
    "    \n",
    "    print(f\"‚úÖ Features Fourier create: {feature_names}\")\n",
    "    return np.array(fourier_features).T, feature_names\n",
    "\n",
    "# Crearea features Fourier\n",
    "fourier_features, fourier_names = create_fourier_features(energy_data, dominant_freqs, top_n=3)\n",
    "print(f\"üìè Shape features Fourier: {fourier_features.shape}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5. Feature Engineering Complet\n",
    "\n",
    "# %%\n",
    "def create_comprehensive_features(df_data, fourier_features, fourier_names):\n",
    "    \"\"\"CreeazƒÉ un set complet de features pentru training\"\"\"\n",
    "    print(\"üîß Creare features comprehensive...\")\n",
    "    \n",
    "    # Scalere pentru diferite tipuri de date\n",
    "    energy_scaler = StandardScaler()\n",
    "    temp_scaler = StandardScaler()\n",
    "    pressure_scaler = StandardScaler()\n",
    "    \n",
    "    # Features de bazƒÉ scalate\n",
    "    energy_scaled = energy_scaler.fit_transform(df_data[['E_tot']]).flatten()\n",
    "    temp_scaled = temp_scaler.fit_transform(df_data[['T']]).flatten()\n",
    "    pressure_scaled = pressure_scaler.fit_transform(df_data[['P']]).flatten()\n",
    "    \n",
    "    # Features derivate pentru energie\n",
    "    energy_diff = np.gradient(energy_scaled)\n",
    "    energy_diff2 = np.gradient(energy_diff)  # Accelera»õie\n",
    "    \n",
    "    # Moving averages (pentru capturarea trend-urilor)\n",
    "    energy_ma5 = pd.Series(energy_scaled).rolling(window=5, center=True).mean().fillna(method='bfill').fillna(method='ffill')\n",
    "    energy_ma10 = pd.Series(energy_scaled).rolling(window=10, center=True).mean().fillna(method='bfill').fillna(method='ffill')\n",
    "    energy_ma20 = pd.Series(energy_scaled).rolling(window=20, center=True).mean().fillna(method='bfill').fillna(method='ffill')\n",
    "    \n",
    "    # Volatilitate (rolling std)\n",
    "    energy_vol5 = pd.Series(energy_scaled).rolling(window=5, center=True).std().fillna(0)\n",
    "    energy_vol10 = pd.Series(energy_scaled).rolling(window=10, center=True).std().fillna(0)\n",
    "    \n",
    "    # Features pentru temperaturƒÉ\n",
    "    temp_diff = np.gradient(temp_scaled)\n",
    "    temp_ma10 = pd.Series(temp_scaled).rolling(window=10, center=True).mean().fillna(method='bfill').fillna(method='ffill')\n",
    "    \n",
    "    # Combinare toate features\n",
    "    all_features = np.column_stack([\n",
    "        energy_scaled,              # Target principal\n",
    "        temp_scaled,                # TemperaturƒÉ\n",
    "        pressure_scaled,            # Presiune\n",
    "        energy_diff,                # Viteza energiei\n",
    "        energy_diff2,               # Accelera»õia energiei\n",
    "        energy_ma5,                 # Trend pe termen scurt\n",
    "        energy_ma10,                # Trend pe termen mediu\n",
    "        energy_ma20,                # Trend pe termen lung\n",
    "        energy_vol5,                # Volatilitate scurtƒÉ\n",
    "        energy_vol10,               # Volatilitate medie\n",
    "        temp_diff,                  # Rata schimbƒÉrii temperaturii\n",
    "        temp_ma10,                  # Trend temperaturƒÉ\n",
    "        fourier_features           # Features Fourier\n",
    "    ])\n",
    "    \n",
    "    # Namen features\n",
    "    feature_names = [\n",
    "        'Energy_scaled', 'Temp_scaled', 'Pressure_scaled',\n",
    "        'Energy_velocity', 'Energy_acceleration',\n",
    "        'Energy_MA5', 'Energy_MA10', 'Energy_MA20',\n",
    "        'Energy_Vol5', 'Energy_Vol10',\n",
    "        'Temp_velocity', 'Temp_MA10'\n",
    "    ] + fourier_names\n",
    "    \n",
    "    print(f\"‚úÖ Total features: {all_features.shape[1]}\")\n",
    "    print(f\"üìã Feature names: {feature_names}\")\n",
    "    \n",
    "    return all_features, feature_names, {\n",
    "        'energy_scaler': energy_scaler,\n",
    "        'temp_scaler': temp_scaler,\n",
    "        'pressure_scaler': pressure_scaler\n",
    "    }\n",
    "\n",
    "# Creare features complete\n",
    "all_features, feature_names, scalers = create_comprehensive_features(df_data, fourier_features, fourier_names)\n",
    "\n",
    "# Verificare pentru NaN sau Inf\n",
    "print(f\"\\nüîç Verificare calitatea features:\")\n",
    "print(f\"NaN values: {np.isnan(all_features).sum()}\")\n",
    "print(f\"Inf values: {np.isinf(all_features).sum()}\")\n",
    "print(f\"Feature range: [{all_features.min():.4f}, {all_features.max():.4f}]\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6. Crearea Secven»õelor pentru LSTM\n",
    "\n",
    "# %%\n",
    "def create_sequences_optimized(features, energy_target, sequence_length, out_steps, overlap_ratio=0.8):\n",
    "    \"\"\"\n",
    "    CreeazƒÉ secven»õe optimizate cu overlap pentru mai multe date de training\n",
    "    \n",
    "    Args:\n",
    "        features: Array cu toate features (include target la coloana 0)\n",
    "        energy_target: Target-ul pentru predic»õie (energia scalatƒÉ)\n",
    "        sequence_length: Lungimea secven»õei input\n",
    "        out_steps: NumƒÉrul de pa»ôi de prezis\n",
    "        overlap_ratio: Raportul de overlap √Æntre secven»õe (0.8 = 80% overlap)\n",
    "    \"\"\"\n",
    "    print(f\"üîß Creare secven»õe cu parametri:\")\n",
    "    print(f\"   - Sequence length: {sequence_length}\")\n",
    "    print(f\"   - Output steps: {out_steps}\")\n",
    "    print(f\"   - Overlap ratio: {overlap_ratio}\")\n",
    "    \n",
    "    sequences, targets = [], []\n",
    "    \n",
    "    # CalculeazƒÉ pas-ul bazat pe overlap\n",
    "    step_size = max(1, int(sequence_length * (1 - overlap_ratio)))\n",
    "    \n",
    "    # GenereazƒÉ secven»õe cu overlap\n",
    "    for i in range(0, len(features) - sequence_length - out_steps + 1, step_size):\n",
    "        # Input sequence (toate features)\n",
    "        seq = features[i:i + sequence_length]\n",
    "        \n",
    "        # Target sequence (doar energia)\n",
    "        target = energy_target[i + sequence_length:i + sequence_length + out_steps]\n",
    "        \n",
    "        if len(target) == out_steps:  # VerificƒÉ cƒÉ target-ul e complet\n",
    "            sequences.append(seq)\n",
    "            targets.append(target)\n",
    "    \n",
    "    sequences = np.array(sequences)\n",
    "    targets = np.array(targets)\n",
    "    \n",
    "    print(f\"‚úÖ Secven»õe create:\")\n",
    "    print(f\"   - Input shape: {sequences.shape}\")\n",
    "    print(f\"   - Target shape: {targets.shape}\")\n",
    "    print(f\"   - Total samples: {len(sequences)}\")\n",
    "    \n",
    "    return sequences, targets\n",
    "\n",
    "# Parametrii optimiza»õi pentru perioada de 50 pa»ôi\n",
    "SEQUENCE_LENGTH = 100  # 2x perioada principalƒÉ\n",
    "OUT_STEPS = 25         # 0.5x perioada pentru predic»õii precise\n",
    "OVERLAP_RATIO = 0.7    # 70% overlap pentru mai multe sample-uri\n",
    "\n",
    "# Crearea secven»õelor\n",
    "energy_target = all_features[:, 0]  # Prima coloanƒÉ e energia scalatƒÉ\n",
    "sequences, targets = create_sequences_optimized(\n",
    "    all_features, \n",
    "    energy_target, \n",
    "    SEQUENCE_LENGTH, \n",
    "    OUT_STEPS,\n",
    "    OVERLAP_RATIO\n",
    ")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7. Construirea Modelului LSTM Avansat\n",
    "\n",
    "# %%\n",
    "def build_advanced_lstm_model(input_shape, out_steps, dropout_rate=0.3):\n",
    "    \"\"\"\n",
    "    Construie»ôte model LSTM avansat optimizat pentru date periodice\n",
    "    \"\"\"\n",
    "    print(f\"üèóÔ∏è Construire model LSTM pentru:\")\n",
    "    print(f\"   - Input shape: {input_shape}\")\n",
    "    print(f\"   - Output steps: {out_steps}\")\n",
    "    print(f\"   - Dropout rate: {dropout_rate}\")\n",
    "    \n",
    "    model = Sequential([\n",
    "        # Layer 1: Bidirectional LSTM pentru capturarea dependin»õelor √Æn ambele direc»õii\n",
    "        Bidirectional(\n",
    "            LSTM(128, return_sequences=True, dropout=dropout_rate, recurrent_dropout=dropout_rate),\n",
    "            input_shape=input_shape,\n",
    "            name='bidirectional_lstm_1'\n",
    "        ),\n",
    "        BatchNormalization(name='batch_norm_1'),\n",
    "        \n",
    "        # Layer 2: Al doilea LSTM bidirectional\n",
    "        Bidirectional(\n",
    "            LSTM(64, return_sequences=True, dropout=dropout_rate, recurrent_dropout=dropout_rate),\n",
    "            name='bidirectional_lstm_2'\n",
    "        ),\n",
    "        BatchNormalization(name='batch_norm_2'),\n",
    "        \n",
    "        # Layer 3: LSTM final\n",
    "        LSTM(32, dropout=dropout_rate, recurrent_dropout=dropout_rate, name='lstm_final'),\n",
    "        BatchNormalization(name='batch_norm_3'),\n",
    "        \n",
    "        # Dense layers cu regularizare\n",
    "        Dense(64, activation='relu', name='dense_1'),\n",
    "        Dropout(dropout_rate + 0.1, name='dropout_1'),\n",
    "        \n",
    "        Dense(32, activation='relu', name='dense_2'),\n",
    "        Dropout(dropout_rate, name='dropout_2'),\n",
    "        \n",
    "        Dense(16, activation='relu', name='dense_3'),\n",
    "        Dropout(dropout_rate * 0.5, name='dropout_3'),\n",
    "        \n",
    "        # Output layer\n",
    "        Dense(out_steps, activation='linear', name='output')\n",
    "    ])\n",
    "    \n",
    "    # Optimizer cu parametri optimiza»õi\n",
    "    optimizer = Adam(\n",
    "        learning_rate=0.001,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "        epsilon=1e-7\n",
    "    )\n",
    "    \n",
    "    # Compilare cu loss function robust\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='huber',  # Mai robust la outliers dec√¢t MSE\n",
    "        metrics=['mae', 'mse', 'mape']\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Model construit cu succes!\")\n",
    "    print(f\"üìä Parametri totali: {model.count_params():,}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Construire model\n",
    "model = build_advanced_lstm_model(\n",
    "    input_shape=(sequences.shape[1], sequences.shape[2]),\n",
    "    out_steps=OUT_STEPS,\n",
    "    dropout_rate=0.3\n",
    ")\n",
    "\n",
    "# Afi»ôare arhitectura modelului\n",
    "model.summary()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 8. √émpƒÉr»õirea Datelor »ôi Antrenarea\n",
    "\n",
    "# %%\n",
    "# Split date (fƒÉrƒÉ shuffle pentru time series)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    sequences, targets, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    shuffle=False  # Important pentru time series\n",
    ")\n",
    "\n",
    "print(f\"üìä √émpƒÉr»õirea datelor:\")\n",
    "print(f\"   - Train samples: {X_train.shape[0]}\")\n",
    "print(f\"   - Test samples: {X_test.shape[0]}\")\n",
    "print(f\"   - Features per sample: {X_train.shape[2]}\")\n",
    "print(f\"   - Sequence length: {X_train.shape[1]}\")\n",
    "\n",
    "# Definire callbacks avansate\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=20,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1,\n",
    "        min_delta=1e-6\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=10,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1,\n",
    "        cooldown=5\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        'best_energy_lstm_model.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "        save_weights_only=False\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"üöÄ √éncepe antrenarea...\")\n",
    "\n",
    "# %% \n",
    "# Antrenare model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Antrenarea completatƒÉ!\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 9. Evaluarea Modelului\n",
    "\n",
    "# %%\n",
    "def evaluate_comprehensive(model, X_test, y_test, scalers, feature_names):\n",
    "    \"\"\"Evaluare comprehensivƒÉ a modelului\"\"\"\n",
    "    print(\"üìà Evaluare model...\")\n",
    "    \n",
    "    # Predic»õii\n",
    "    y_pred = model.predict(X_test, verbose=0)\n",
    "    \n",
    "    # Scalare inversƒÉ pentru metrici √Æn unitƒÉ»õi originale\n",
    "    energy_scaler = scalers['energy_scaler']\n",
    "    \n",
    "    # Flatten pentru calcularea metricilor\n",
    "    y_test_flat = y_test.flatten().reshape(-1, 1)\n",
    "    y_pred_flat = y_pred.flatten().reshape(-1, 1)\n",
    "    \n",
    "    # Scalare inversƒÉ\n",
    "    y_test_original = energy_scaler.inverse_transform(y_test_flat).flatten()\n",
    "    y_pred_original = energy_scaler.inverse_transform(y_pred_flat).flatten()\n",
    "    \n",
    "    # Calculare metrici\n",
    "    mse = mean_squared_error(y_test_original, y_pred_original)\n",
    "    mae = mean_absolute_error(y_test_original, y_pred_original)\n",
    "    r2 = r2_score(y_test_original, y_pred_original)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    # MAPE (Mean Absolute Percentage Error)\n",
    "    mape = np.mean(np.abs((y_test_original - y_pred_original) / y_test_original)) * 100\n",
    "    \n",
    "    print(f\"üèÜ Performan»õa modelului:\")\n",
    "    print(f\"   ‚îú‚îÄ‚îÄ MSE: {mse:.8f}\")\n",
    "    print(f\"   ‚îú‚îÄ‚îÄ MAE: {mae:.8f}\")\n",
    "    print(f\"   ‚îú‚îÄ‚îÄ RMSE: {rmse:.8f}\")\n",
    "    print(f\"   ‚îú‚îÄ‚îÄ R¬≤: {r2:.6f}\")\n",
    "    print(f\"   ‚îî‚îÄ‚îÄ MAPE: {mape:.4f}%\")\n",
    "    \n",
    "    # Analiza reziduurilor\n",
    "    residuals = y_pred_original - y_test_original\n",
    "    print(f\"\\nüìä Analiza reziduurilor:\")\n",
    "    print(f\"   ‚îú‚îÄ‚îÄ Mean residual: {np.mean(residuals):.8f}\")\n",
    "    print(f\"   ‚îú‚îÄ‚îÄ Std residual: {np.std(residuals):.8f}\")\n",
    "    print(f\"   ‚îú‚îÄ‚îÄ Min residual: {np.min(residuals):.8f}\")\n",
    "    print(f\"   ‚îî‚îÄ‚îÄ Max residual: {np.max(residuals):.8f}\")\n",
    "    \n",
    "    return {\n",
    "        'predictions': y_pred,\n",
    "        'predictions_original': y_pred_original,\n",
    "        'targets_original': y_test_original,\n",
    "        'residuals': residuals,\n",
    "        'metrics': {\n",
    "            'mse': mse,\n",
    "            'mae': mae,\n",
    "            'rmse': rmse,\n",
    "            'r2': r2,\n",
    "            'mape': mape\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Evaluare model\n",
    "results = evaluate_comprehensive(model, X_test, y_test, scalers, feature_names)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 10. VizualizƒÉri Complete\n",
    "\n",
    "# %%\n",
    "def create_comprehensive_plots(results, history):\n",
    "    \"\"\"CreeazƒÉ vizualizƒÉri complete pentru analiza modelului\"\"\"\n",
    "    print(\"üìä Creare vizualizƒÉri...\")\n",
    "    \n",
    "    # Extrage rezultatele\n",
    "    y_pred_orig = results['predictions_original']\n",
    "    y_test_orig = results['targets_original']\n",
    "    residuals = results['residuals']\n",
    "    metrics = results['metrics']\n",
    "    \n",
    "    # 1. Plot principal cu 4 subplots\n",
    "    fig = sp.make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=[\n",
    "            'Predic»õii vs Realitate', \n",
    "            'Training History', \n",
    "            'Distribu»õie Reziduuri', \n",
    "            'Time Series Comparison'\n",
    "        ],\n",
    "        specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "               [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
    "    )\n",
    "    \n",
    "    # 1a. Scatter plot predic»õii vs realitate\n",
    "    sample_size = min(2000, len(y_test_orig))\n",
    "    indices = np.random.choice(len(y_test_orig), sample_size, replace=False)\n",
    "    y_test_sample = y_test_orig[indices]\n",
    "    y_pred_sample = y_pred_orig[indices]\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=y_test_sample, \n",
    "            y=y_pred_sample, \n",
    "            mode='markers', \n",
    "            name=f'Predic»õii (R¬≤={metrics[\"r2\"]:.4f})',\n",
    "            marker=dict(size=4, opacity=0.6, color='blue'),\n",
    "            hovertemplate='Real: %{x:.6f}<br>Pred: %{y:.6f}<extra></extra>'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Linia perfectƒÉ\n",
    "    min_val, max_val = min(y_test_sample.min(), y_pred_sample.min()), max(y_test_sample.max(), y_pred_sample.max())\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[min_val, max_val], \n",
    "            y=[min_val, max_val],\n",
    "            mode='lines', \n",
    "            name='Perfect Fit', \n",
    "            line=dict(dash='dash', color='red')\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # 1b. Training history\n",
    "    fig.add_trace(\n",
    "        go.Scatter(y=history.history['loss'], name='Train Loss', line=dict(color='blue')),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(y=history.history['val_loss'], name='Val Loss', line=dict(color='red')),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # 1c. HistogramƒÉ reziduuri\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=residuals[indices], \n",
    "            name='Reziduuri', \n",
    "            nbinsx=50,\n",
    "            marker=dict(color='green', opacity=0.7)\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # 1d. Time series comparison (primele 500 puncte)\n",
    "    time_sample = min(500, len(y_test_orig))\n",
    "    x_time = np.arange(time_sample)\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=x_time, y=y_test_orig[:time_sample], name='Original', \n",
    "                  line=dict(color='blue', width=2)),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=x_time, y=y_pred_orig[:time_sample], name='Predic»õie', \n",
    "                  line=dict(color='red', width=2, dash='dot')),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        height=800, \n",
    "        title_text=f\"AnalizƒÉ CompletƒÉ Model LSTM - MAE: {metrics['mae']:.6f}, R¬≤: {metrics['r2']:.4f}\",\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    # Labels pentru axe\n",
    "    fig.update_xaxes(title_text=\"Valori Reale\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Predic»õii\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"EpocƒÉ\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Loss\", row=1, col=2)\n",
    "    fig.update_xaxes(title_text=\"Reziduuri\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Frecven»õƒÉ\", row=2, col=1)\n",
    "    fig.update_xaxes(title_text=\"Timp\", row=2, col=2)\n",
    "    fig.update_yaxes(title_text=\"Energie\", row=2, col=2)\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # 2. Plot separat pentru analiza FFT a predic»õiilor\n",
    "    create_fft_analysis_plot(y_test_orig, y_pred_orig)\n",
    "\n",
    "def create_fft_analysis_plot(y_test_orig, y_pred_orig):\n",
    "    \"\"\"AnalizƒÉ FFT a predic»õiilor vs realitate\"\"\"\n",
    "    \n",
    "    # FFT pentru o subsec»õiune reprezentativƒÉ\n",
    "    sample_size = min(2048, len(y_test_orig))  # Putere de 2 pentru FFT eficient\n",
    "    \n",
    "    y_test_sample = y_test_orig[:sample_size]\n",
    "    y_pred_sample = y_pred_orig[:sample_size]\n",
    "    \n",
    "    # Calculare FFT\n",
    "    fft_test = np.abs(fft(y_test_sample))[:sample_size//2]\n",
    "    fft_pred = np.abs(fft(y_pred_sample))[:sample_size//2]\n",
    "    freqs = fftfreq(sample_size)[:sample_size//2]\n",
    "    \n",
    "    # Plot\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=freqs, \n",
    "            y=fft_test, \n",
    "            name='FFT Original', \n",
    "            line=dict(color='blue', width=2)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=freqs, \n",
    "            y=fft_pred, \n",
    "            name='FFT Predic»õii', \n",
    "            line=dict(color='red', width=2, dash='dash')\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Eviden»õiazƒÉ frecven»õa dominantƒÉ cunoscutƒÉ (0.02 Hz)\n",
    "    fig.add_vline(\n",
    "        x=0.02, \n",
    "        line_dash=\"dot\", \n",
    "        line_color=\"green\",\n",
    "        annotation_text=\"Freq dominantƒÉ (0.02 Hz)\"\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Compara»õie FFT: Original vs Predic»õii\",\n",
    "        xaxis_title=\"Frecven»õa (Hz)\",\n",
    "        yaxis_title=\"Amplitudine\",\n",
    "        height=500,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    # Zoom pe regiunea de interes (0-0.1 Hz)\n",
    "    fig.update_xaxes(range=[0, 0.1])\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "# Rulare vizualizƒÉri\n",
    "create_comprehensive_plots(results, history)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 11. Predic»õii pe Date Noi »ôi Validare\n",
    "\n",
    "# %%\n",
    "def make_future_predictions(model, last_sequence, scalers, n_future_steps=100):\n",
    "    \"\"\"\n",
    "    CreeazƒÉ predic»õii pentru viitor folosind ultimele date\n",
    "    \"\"\"\n",
    "    print(f\"üîÆ Predic»õii pentru urmƒÉtorii {n_future_steps} pa»ôi...\")\n",
    "    \n",
    "    # Folose»ôte ultima secven»õƒÉ din datele de test\n",
    "    current_sequence = last_sequence.copy()\n",
    "    future_predictions = []\n",
    "    \n",
    "    # Predic»õie pas cu pas\n",
    "    for step in range(n_future_steps):\n",
    "        # Predic»õia pentru urmƒÉtorii OUT_STEPS\n",
    "        pred = model.predict(current_sequence.reshape(1, current_sequence.shape[0], current_sequence.shape[1]), verbose=0)\n",
    "        \n",
    "        # Ia doar primul pas prezis\n",
    "        next_energy = pred[0, 0]\n",
    "        future_predictions.append(next_energy)\n",
    "        \n",
    "        # ActualizeazƒÉ secven»õa (remove primul element, add predic»õia)\n",
    "        # Pentru simplitate, pƒÉstrƒÉm doar energia (coloana 0) »ôi aproximƒÉm restul features\n",
    "        new_row = current_sequence[-1].copy()\n",
    "        new_row[0] = next_energy  # Update energia\n",
    "        \n",
    "        # Update secven»õa\n",
    "        current_sequence = np.vstack([current_sequence[1:], new_row])\n",
    "    \n",
    "    # Scalare inversƒÉ pentru unitƒÉ»õi originale\n",
    "    future_predictions = np.array(future_predictions).reshape(-1, 1)\n",
    "    future_predictions_original = scalers['energy_scaler'].inverse_transform(future_predictions).flatten()\n",
    "    \n",
    "    return future_predictions_original\n",
    "\n",
    "# CreeazƒÉ predic»õii pentru viitor\n",
    "last_test_sequence = X_test[-1]  # Ultima secven»õƒÉ din test\n",
    "future_pred = make_future_predictions(model, last_test_sequence, scalers, n_future_steps=100)\n",
    "\n",
    "# VizualizeazƒÉ predic»õiile viitoare\n",
    "fig = go.Figure()\n",
    "\n",
    "# Ultimele valori cunoscute\n",
    "known_values = scalers['energy_scaler'].inverse_transform(\n",
    "    y_test[-10:].flatten().reshape(-1, 1)\n",
    ").flatten()\n",
    "\n",
    "x_known = np.arange(-len(known_values), 0)\n",
    "x_future = np.arange(0, len(future_pred))\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x_known, \n",
    "        y=known_values, \n",
    "        name='Valori Cunoscute',\n",
    "        line=dict(color='blue', width=3),\n",
    "        mode='lines+markers'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x_future, \n",
    "        y=future_pred, \n",
    "        name='Predic»õii Viitoare',\n",
    "        line=dict(color='red', width=2, dash='dash'),\n",
    "        mode='lines+markers'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_vline(x=0, line_dash=\"dot\", line_color=\"black\", annotation_text=\"Prezent\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Predic»õii pentru Viitor - Energie CineticƒÉ\",\n",
    "    xaxis_title=\"Pa»ôi de Timp\",\n",
    "    yaxis_title=\"Energie TotalƒÉ\",\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(f\"üìä Statistici predic»õii viitoare:\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ Min: {future_pred.min():.6f}\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ Max: {future_pred.max():.6f}\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ Mean: {future_pred.mean():.6f}\")\n",
    "print(f\"   ‚îî‚îÄ‚îÄ Std: {future_pred.std():.6f}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 12. Analiza Importan»õei Features\n",
    "\n",
    "# %%\n",
    "def analyze_feature_importance_approximation(model, X_test, y_test, feature_names, n_samples=100):\n",
    "    \"\"\"\n",
    "    AnalizƒÉ aproximativƒÉ a importan»õei features prin permutare\n",
    "    \"\"\"\n",
    "    print(\"üîç AnalizƒÉ importan»õƒÉ features (aproximativƒÉ)...\")\n",
    "    \n",
    "    # Baseline performance\n",
    "    baseline_pred = model.predict(X_test[:n_samples], verbose=0)\n",
    "    baseline_mse = mean_squared_error(y_test[:n_samples].flatten(), baseline_pred.flatten())\n",
    "    \n",
    "    feature_importance = {}\n",
    "    \n",
    "    # Pentru fiecare feature\n",
    "    for i, feature_name in enumerate(feature_names):\n",
    "        print(f\"   Testing feature: {feature_name}\")\n",
    "        \n",
    "        # CreeazƒÉ o copie »ôi amestecƒÉ feature-ul\n",
    "        X_permuted = X_test[:n_samples].copy()\n",
    "        X_permuted[:, :, i] = np.random.permutation(X_permuted[:, :, i].flatten()).reshape(X_permuted[:, :, i].shape)\n",
    "        \n",
    "        # CalculeazƒÉ performan»õa cu feature-ul amestecat\n",
    "        permuted_pred = model.predict(X_permuted, verbose=0)\n",
    "        permuted_mse = mean_squared_error(y_test[:n_samples].flatten(), permuted_pred.flatten())\n",
    "        \n",
    "        # Importan»õa = c√¢t de mult se degradeazƒÉ performan»õa\n",
    "        importance = permuted_mse - baseline_mse\n",
    "        feature_importance[feature_name] = importance\n",
    "    \n",
    "    # SorteazƒÉ »ôi afi»ôeazƒÉ\n",
    "    sorted_importance = dict(sorted(feature_importance.items(), key=lambda x: x[1], reverse=True))\n",
    "    \n",
    "    print(f\"\\nüèÜ Top 10 features importante:\")\n",
    "    for i, (feature, importance) in enumerate(list(sorted_importance.items())[:10]):\n",
    "        print(f\"   {i+1:2d}. {feature:20s}: {importance:.8f}\")\n",
    "    \n",
    "    # Plot importan»õa\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    features = list(sorted_importance.keys())[:15]  # Top 15\n",
    "    importances = [sorted_importance[f] for f in features]\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=importances,\n",
    "            y=features,\n",
    "            orientation='h',\n",
    "            marker=dict(color=importances, colorscale='Viridis')\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Importan»õa Features (Top 15)\",\n",
    "        xaxis_title=\"Degradarea MSE\",\n",
    "        yaxis_title=\"Features\",\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    return sorted_importance\n",
    "\n",
    "# AnalizƒÉ importan»õƒÉ features\n",
    "feature_importance = analyze_feature_importance_approximation(\n",
    "    model, X_test, y_test, feature_names, n_samples=200\n",
    ")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 13. Salvarea Modelului »ôi Configura»õiei\n",
    "\n",
    "# %%\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "def save_model_and_config(model, scalers, feature_names, results, config_info):\n",
    "    \"\"\"SalveazƒÉ modelul »ôi toate configura»õiile\"\"\"\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    base_name = f\"energy_lstm_model_{timestamp}\"\n",
    "    \n",
    "    print(f\"üíæ Salvare model »ôi configura»õie cu timestamp: {timestamp}\")\n",
    "    \n",
    "    # 1. Salvare model TensorFlow\n",
    "    model.save(f\"{base_name}.h5\")\n",
    "    print(f\"‚úÖ Model salvat: {base_name}.h5\")\n",
    "    \n",
    "    # 2. Salvare scalers\n",
    "    with open(f\"{base_name}_scalers.pkl\", 'wb') as f:\n",
    "        pickle.dump(scalers, f)\n",
    "    print(f\"‚úÖ Scalers salva»õi: {base_name}_scalers.pkl\")\n",
    "    \n",
    "    # 3. Salvare configura»õie »ôi rezultate\n",
    "    config = {\n",
    "        'model_info': {\n",
    "            'sequence_length': SEQUENCE_LENGTH,\n",
    "            'output_steps': OUT_STEPS,\n",
    "            'overlap_ratio': OVERLAP_RATIO,\n",
    "            'total_features': len(feature_names),\n",
    "            'training_samples': len(X_train),\n",
    "            'test_samples': len(X_test)\n",
    "        },\n",
    "        'feature_names': feature_names,\n",
    "        'performance_metrics': results['metrics'],\n",
    "        'training_config': {\n",
    "            'epochs_completed': len(history.history['loss']),\n",
    "            'final_train_loss': float(history.history['loss'][-1]),\n",
    "            'final_val_loss': float(history.history['val_loss'][-1]),\n",
    "            'best_val_loss': float(min(history.history['val_loss']))\n",
    "        },\n",
    "        'data_info': config_info,\n",
    "        'timestamp': timestamp\n",
    "    }\n",
    "    \n",
    "    with open(f\"{base_name}_config.json\", 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    print(f\"‚úÖ Configura»õie salvatƒÉ: {base_name}_config.json\")\n",
    "    \n",
    "    return base_name\n",
    "\n",
    "# Informa»õii despre date pentru salvare\n",
    "data_config = {\n",
    "    'source_file': my_file,\n",
    "    'total_data_points': len(df_data),\n",
    "    'energy_range': [float(df_data['E_tot'].min()), float(df_data['E_tot'].max())],\n",
    "    'temperature_range': [float(df_data['T'].min()), float(df_data['T'].max())],\n",
    "    'dominant_frequency_hz': float(dominant_freqs[0]) if len(dominant_freqs) > 0 else None,\n",
    "    'dominant_period_steps': float(1/dominant_freqs[0]) if len(dominant_freqs) > 0 and dominant_freqs[0] != 0 else None\n",
    "}\n",
    "\n",
    "# Salvare completƒÉ\n",
    "saved_model_name = save_model_and_config(model, scalers, feature_names, results, data_config)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 14. Func»õie pentru √éncƒÉrcarea »ôi Utilizarea Modelului Salvat\n",
    "\n",
    "# %%\n",
    "def load_trained_model(base_name):\n",
    "    \"\"\"√éncarcƒÉ un model antrenat anterior\"\"\"\n",
    "    print(f\"üìÇ √éncƒÉrcare model: {base_name}\")\n",
    "    \n",
    "    try:\n",
    "        # √éncƒÉrcare model\n",
    "        model = tf.keras.models.load_model(f\"{base_name}.h5\")\n",
    "        print(f\"‚úÖ Model √ÆncƒÉrcat\")\n",
    "        \n",
    "        # √éncƒÉrcare scalers\n",
    "        with open(f\"{base_name}_scalers.pkl\", 'rb') as f:\n",
    "            scalers = pickle.load(f)\n",
    "        print(f\"‚úÖ Scalers √ÆncƒÉrca»õi\")\n",
    "        \n",
    "        # √éncƒÉrcare configura»õie\n",
    "        with open(f\"{base_name}_config.json\", 'r') as f:\n",
    "            config = json.load(f)\n",
    "        print(f\"‚úÖ Configura»õie √ÆncƒÉrcatƒÉ\")\n",
    "        \n",
    "        print(f\"üìä Model info:\")\n",
    "        print(f\"   ‚îú‚îÄ‚îÄ Features: {config['model_info']['total_features']}\")\n",
    "        print(f\"   ‚îú‚îÄ‚îÄ Sequence length: {config['model_info']['sequence_length']}\")\n",
    "        print(f\"   ‚îú‚îÄ‚îÄ Output steps: {config['model_info']['output_steps']}\")\n",
    "        print(f\"   ‚îú‚îÄ‚îÄ Performance R¬≤: {config['performance_metrics']['r2']:.4f}\")\n",
    "        print(f\"   ‚îî‚îÄ‚îÄ Performance MAE: {config['performance_metrics']['mae']:.6f}\")\n",
    "        \n",
    "        return model, scalers, config\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Eroare la √ÆncƒÉrcare: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Exemplu de utilizare (decomenteazƒÉ pentru a testa)\n",
    "# loaded_model, loaded_scalers, loaded_config = load_trained_model(saved_model_name)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 15. Func»õie pentru Predic»õii pe Date Noi\n",
    "\n",
    "# %%\n",
    "def predict_energy_sequence(model, scalers, feature_names, new_data, sequence_length):\n",
    "    \"\"\"\n",
    "    Func»õie pentru predic»õii pe date complet noi\n",
    "    \n",
    "    Args:\n",
    "        model: Modelul antrenat\n",
    "        scalers: Scalers pentru normalizare\n",
    "        feature_names: Lista cu numele features\n",
    "        new_data: DataFrame cu date noi (trebuie sƒÉ aibƒÉ coloanele: E_tot, T, P)\n",
    "        sequence_length: Lungimea secven»õei de input\n",
    "    \"\"\"\n",
    "    print(f\"üîÆ Predic»õii pe {len(new_data)} puncte noi...\")\n",
    "    \n",
    "    try:\n",
    "        # VerificƒÉ cƒÉ datele au coloanele necesare\n",
    "        required_cols = ['E_tot', 'T', 'P']\n",
    "        if not all(col in new_data.columns for col in required_cols):\n",
    "            raise ValueError(f\"Datele trebuie sƒÉ con»õinƒÉ coloanele: {required_cols}\")\n",
    "        \n",
    "        # Recreate features similar cu training\n",
    "        energy_scaled = scalers['energy_scaler'].transform(new_data[['E_tot']]).flatten()\n",
    "        temp_scaled = scalers['temp_scaler'].transform(new_data[['T']]).flatten()\n",
    "        pressure_scaled = scalers['pressure_scaler'].transform(new_data[['P']]).flatten()\n",
    "        \n",
    "        # Features derivate\n",
    "        energy_diff = np.gradient(energy_scaled)\n",
    "        energy_diff2 = np.gradient(energy_diff)\n",
    "        \n",
    "        energy_ma5 = pd.Series(energy_scaled).rolling(window=5, center=True).mean().fillna(method='bfill').fillna(method='ffill')\n",
    "        energy_ma10 = pd.Series(energy_scaled).rolling(window=10, center=True).mean().fillna(method='bfill').fillna(method='ffill')\n",
    "        energy_ma20 = pd.Series(energy_scaled).rolling(window=20, center=True).mean().fillna(method='bfill').fillna(method='ffill')\n",
    "        \n",
    "        energy_vol5 = pd.Series(energy_scaled).rolling(window=5, center=True).std().fillna(0)\n",
    "        energy_vol10 = pd.Series(energy_scaled).rolling(window=10, center=True).std().fillna(0)\n",
    "        \n",
    "        temp_diff = np.gradient(temp_scaled)\n",
    "        temp_ma10 = pd.Series(temp_scaled).rolling(window=10, center=True).mean().fillna(method='bfill').fillna(method='ffill')\n",
    "        \n",
    "        # Features Fourier (aproximare - ar trebui sƒÉ fie calculate similar cu training)\n",
    "        fourier_features, _ = create_fourier_features(energy_scaled, dominant_freqs, top_n=3)\n",
    "        \n",
    "        # Combine toate features\n",
    "        all_features = np.column_stack([\n",
    "            energy_scaled, temp_scaled, pressure_scaled,\n",
    "            energy_diff, energy_diff2,\n",
    "            energy_ma5, energy_ma10, energy_ma20,\n",
    "            energy_vol5, energy_vol10,\n",
    "            temp_diff, temp_ma10,\n",
    "            fourier_features\n",
    "        ])\n",
    "        \n",
    "        predictions = []\n",
    "        \n",
    "        # Predic»õii pentru fiecare secven»õƒÉ posibilƒÉ\n",
    "        for i in range(len(all_features) - sequence_length + 1):\n",
    "            seq = all_features[i:i + sequence_length].reshape(1, sequence_length, -1)\n",
    "            pred = model.predict(seq, verbose=0)\n",
    "            predictions.append(pred[0])\n",
    "        \n",
    "        # Scalare inversƒÉ\n",
    "        predictions = np.array(predictions)\n",
    "        predictions_original = scalers['energy_scaler'].inverse_transform(\n",
    "            predictions.reshape(-1, 1)\n",
    "        ).reshape(predictions.shape)\n",
    "        \n",
    "        print(f\"‚úÖ {len(predictions)} predic»õii generate\")\n",
    "        \n",
    "        return predictions_original\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Eroare la predic»õie: {e}\")\n",
    "        return None\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 16. Rezumat Final »ôi RecomandƒÉri\n",
    "\n",
    "# %%\n",
    "print(\"üéØ REZUMAT FINAL - ANALIZA TIME SERIES ENERGIE CINETICƒÇ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüìä PERFORMAN»öA MODELULUI:\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ R¬≤ Score: {results['metrics']['r2']:.6f}\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ Mean Absolute Error: {results['metrics']['mae']:.8f}\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ Root Mean Square Error: {results['metrics']['rmse']:.8f}\")\n",
    "print(f\"   ‚îî‚îÄ‚îÄ Mean Absolute Percentage Error: {results['metrics']['mape']:.4f}%\")\n",
    "\n",
    "print(f\"\\nüîß CONFIGURA»öIA OPTIMALƒÇ:\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ Sequence Length: {SEQUENCE_LENGTH} pa»ôi (2√ó perioada principalƒÉ)\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ Output Steps: {OUT_STEPS} pa»ôi (0.5√ó perioada)\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ Total Features: {len(feature_names)}\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ Overlap Ratio: {OVERLAP_RATIO} ({int(OVERLAP_RATIO*100)}%)\")\n",
    "print(f\"   ‚îî‚îÄ‚îÄ Training Samples: {len(X_train):,}\")\n",
    "\n",
    "print(f\"\\nüåä ANALIZA FOURIER:\")\n",
    "if len(dominant_freqs) > 0:\n",
    "    print(f\"   ‚îú‚îÄ‚îÄ Frecven»õa dominantƒÉ: {dominant_freqs[0]:.6f} Hz\")\n",
    "    print(f\"   ‚îú‚îÄ‚îÄ Perioada principalƒÉ: {1/dominant_freqs[0]:.2f} pa»ôi\")\n",
    "    print(f\"   ‚îî‚îÄ‚îÄ Features Fourier generate: {len([f for f in feature_names if 'sin_' in f or 'cos_' in f])}\")\n",
    "\n",
    "print(f\"\\nüí° RECOMANDƒÇRI PENTRU OPTIMIZARE ULTERIOARƒÇ:\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ ExperimenteazƒÉ cu arhitecturi Transformer pentru capturarea dependin»õelor\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ √éncearcƒÉ ensemble methods cu multiple modele LSTM\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ ConsiderƒÉ attention mechanisms pentru features importante\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ TesteazƒÉ data augmentation prin rota»õii de fazƒÉ\")\n",
    "print(f\"   ‚îî‚îÄ‚îÄ ExploreazƒÉ autoencoder pentru detec»õia anomaliilor\")\n",
    "\n",
    "print(f\"\\nüìÅ FI»òIERE SALVATE:\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ Model: {saved_model_name}.h5\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ Scalers: {saved_model_name}_scalers.pkl\")\n",
    "print(f\"   ‚îî‚îÄ‚îÄ Config: {saved_model_name}_config.json\")\n",
    "\n",
    "print(f\"\\nüöÄ URMƒÇTORII PA»òI:\")\n",
    "print(f\"   1. TesteazƒÉ modelul pe date complet noi\")\n",
    "print(f\"   2. ImplementeazƒÉ monitoring √Æn timp real\")\n",
    "print(f\"   3. OptimizeazƒÉ hiperparametrii cu Optuna/Hyperopt\")\n",
    "print(f\"   4. DezvoltƒÉ API pentru predic»õii √Æn produc»õie\")\n",
    "\n",
    "print(\"\\n‚úÖ ANALIZA COMPLETƒÇ FINALIZATƒÇ!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf216",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
